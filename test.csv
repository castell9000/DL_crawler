,Title,Abstract,Paper url,Author,Keyword,Publish_date,Volume,Issue,Pages
0,Machine learning techniques for business blog search and mining,"Weblogs, or blogs, have rapidly gained in popularity over the past few years. In particular, the growth of business blogs that are written by or provide commentary on businesses and companies opens up new opportunities for developing blog-specific search and mining techniques. In this paper, we propose probabilistic models for blog search and mining using two machine learning techniques, latent semantic analysis (LSA) and probabilistic latent semantic analysis (PLSA). We implement the models in our database of business blogs, BizBlogs07, with the aim of achieving higher precision and recall. The probabilistic model is able to segment the business blogs into separate topic areas, which is useful for keywords detection on the blogosphere. Various term-weighting schemes and factor values were also studied in detail, which reveal interesting patterns in our database of business blogs. Our multi-functional business blog system is indeed found to be very different from existing blog search engines, as it aims to provide better relevance and precision of the search.",https://www.sciencedirect.com/science/article/pii/S0957417407002709,"Yun Chen, Flora S. Tsai, Kap Luk Chan, ","Latent semantic analysis, Probabilistic latent semantic analysis, Weblog, Blog, Data mining",['2008'],['35'],['3'],581-590
1,Automated diagnosis of sewer pipe defects based on machine learning approaches,"In sewage rehabilitation planning, closed circuit television (CCTV) systems are the widely used inspection tools in assessing sewage structural conditions for non man entry pipes. Currently, the assessment of sewage structural conditions by manually interpretation on CCTV images seems inefficient, especially for several thousands of frames in one inspection plan. Also, the assessment work significantly involves engineers’ eye sight and professional experience. With a purpose of assisting general staffs in diagnosing pipe defects on CCTV inspection images, a diagnostic system by applying machine learning approaches is proposed in this paper. This research was first to use image process techniques, including wavelet transform and computation of co-occurrence matrices, for describing the textures of the pipe defects. Then, three neural network approaches, back-propagation neural network (BPN), radial basis network (RBN), and support vector machine (SVM), were adopted to classify pipe defect patterns, and their performances were compared and discussed. The diagnostic system of pipe defects was applied to a sewer system in the 9th district, Taichung City which is the largest city in middle Taiwan. The result shows that the diagnosis accuracy of 60% derived by SVM is the best and also better than the diagnosis accuracy of 57.4% derived by a Bayesian classifier.",https://www.sciencedirect.com/science/article/pii/S0957417407003405,"Ming-Der Yang, Tung-Ching Su, ","CCTV images, Sewer pipe defects, Diagnostic system, Textural features",['2008'],['35'],['3'],1327-1337
2,A cascade learning system for classification of diabetes disease: Generalized Discriminant Analysis and Least Square Support Vector Machine,"The aim of this study is to diagnosis of diabetes disease, which is one of the most important diseases in medical field using Generalized Discriminant Analysis (GDA) and Least Square Support Vector Machine (LS-SVM). Also, we proposed a new cascade learning system based on Generalized Discriminant Analysis and Least Square Support Vector Machine. The proposed system consists of two stages. The first stage, we have used Generalized Discriminant Analysis to discriminant feature variables between healthy and patient (diabetes) data as pre-processing process. The second stage, we have used LS-SVM in order to classification of diabetes dataset. While LS-SVM obtained 78.21% classification accuracy using 10-fold cross validation, the proposed system called GDA–LS-SVM obtained 82.05% classification accuracy using 10-fold cross validation. The robustness of the proposed system is examined using classification accuracy, k-fold cross-validation method and confusion matrix. The obtained classification accuracy is 82.05% and it is very promising compared to the previously reported classification techniques.",https://www.sciencedirect.com/science/article/pii/S0957417406002995,"Kemal Polat, Salih Güneş, Ahmet Arslan, ","Generalized discriminant analysis, Least Square Support Vector Machine, Expert systems, Pima Indians diabetes dataset",['2008'],['34'],['1'],482-487
3,A non-parametric learning algorithm for small manufacturing data sets,"Nowadays the manufacturing environment changes promptly owing to globalization and innovation. It is noteworthy that the life cycle of products consequently becomes shorter and shorter. Although data mining techniques are widely employed by researchers to extract proper management information from the data, scarce data can only be obtained in the early stages of a manufacturing system.From the view of machine learning, the size of training data significantly influences the learning accuracies. Learning based on limited experience will be a tough task. On account of the cause, this research systematically estimates the data behavior such as the trend and potency to capture the dependency within a sequence of time series data. It should also be added that the analyzed data in this article are dependent examples that come from different populations. This research proposes a non-parametric learning algorithm instead of using parametric statistics for small-data-set learning. The proposed algorithm named the trend and potency tracking method (TPTM) attempts to explore the predictive information through the generation of trend and potency (TP) value of each datum. The extra information extracted from the data trend and potency proves that it can speed up stabilizing the learning task and can dynamically improve the derived knowledge from the occurrence of the latest data.",https://www.sciencedirect.com/science/article/pii/S0957417406002880,"Der-Chang Li, Chun-Wu Yeh, ","Trend and potency function, Small data sets, Non-parametric learning, Machine learning",['2008'],['34'],['1'],391-398
4,Learning cross-level certain and possible rules by rough sets,"Machine learning can extract desired knowledge and ease the development bottleneck in building expert systems. Among the proposed approaches, deriving rules from training examples is the most common. Given a set of examples, a learning program tries to induce rules that describe each class. Recently, the rough-set theory has been widely used in dealing with data classification problems. Most of the previous studies on rough sets focused on deriving certain rules and possible rules on the single concept level. Data with hierarchical attribute values are, however, commonly seen in real-world applications. This paper thus attempts to propose a new learning algorithm based on rough sets to find cross-level certain and possible rules from training data with hierarchical attribute values. It is more complex than learning rules from training examples with single-level values, but may derive more general knowledge from data. Boundary approximations, instead of upper approximations, are used to find possible rules, thus reducing some subsumption checking. Some pruning heuristics are also adopted in the proposed algorithm to avoid unnecessary search.",https://www.sciencedirect.com/science/article/pii/S0957417407000474,"Tzung-Pei Hong, Chun-E Lin, Jiann-Horng Lin, Shyue-Liang Wang, ","Machine learning, Rough set, Certain rule, Possible rule, Hierarchical value",['2008'],['34'],['3'],1698-1706
5,An algorithm to cluster data for efficient classification of support vector machines,"Support vector machines (SVM) are widely applied to various classification problems. However, most SVM need lengthy computation time when faced with a large and complicated dataset. This research develops a clustering algorithm for efficient learning. The method mainly categorizes data into clusters, and finds critical data in clusters as a substitute for the original data to reduce the computational complexity. The computational experiments presented in this paper show that the clustering algorithm significantly advances SVM learning efficiency.",https://www.sciencedirect.com/science/article/pii/S0957417407000796,"Der-Chiang Li, Yao-Hwei Fang, ","Density-based clustering algorithm, Machine learning, Support vector machines, Computational complexity",['2008'],['34'],['3'],2013-2018
6,Supporting the development of collaborative problem-based learning environments with an intelligent diagnosis tool,"Problem-based learning (PBL) has been implemented for years in lots of countries and the achieved performance is plausible. However, the implementation of PBL course often needs a lot of human resources; the instructors often need offering instructions to the learners intensively. As the modern computer science and the Internet gains wide popularity around the world, e-learning is taken by the learners as an important study aid and thereby lightens the burden of the instructors. In this research, we incorporate the PBL activity into an open software e-learning platform, Moodle, and a learning diagnosis tool is added in the platform to alleviate the loading of the instructors. The learners’ transcripts posted on discussion board and chatting room are first preprocessed by the learning parameter extraction module to truly reflect the learners’ planning on the solutions to the designated problem. The extracted parameters are further fed into a classification algorithm to examine the quality of the learners’ suggestions and some appropriate feedback will be issued to the learners/instructor if needed. The experimental results show that the text mining and machine learning techniques used in this work are effective in automatically providing useful feedback for the learners to progress through the ill-structured problem solving.",https://www.sciencedirect.com/science/article/pii/S0957417407002746,"Chenn-Jung Huang, Yi-Ta Chuang, ","Agents, Problem solving, Collaboration, Text mining, Support Vector Machines, Cognitive style",['2008'],['35'],['3'],622-631
7,ReviewA new training method for support vector machines: Clustering k-NN support vector machines,"For training of support vector machines (SVMs) efficiently, a new training algorithm, clustering k-NN (k-nearest neighbor) support vector machines (CKSVMs) based on a Gaussian function regulated locally is proposed. In order to reflect degree of training data point as a support vector the Gaussian function is used with k-nearest neighbor (k-NN) method and Euclidean Distance measure. To add local control property to the training algorithm, a simple clustering scheme is implemented before Gaussian functions are constructed for each cluster. In addition, probabilistic SVM outputs are used for extension from binary classification to multi-class classification in pairwise approach. This training algorithm is applied to three commonly used classification problems. Experimental results show that the CKSVM has more classification accuracy than standard multi-class LS-SVM, FLS-SVM and LS-SVM with k-NN method which is proposed in our previous study. In addition to this, the training algorithm highly improved efficiency of the SVM classifier via simple algorithm.",https://www.sciencedirect.com/science/article/pii/S0957417407003193,"Emre Çomak, Ahmet Arslan, ","Support vector machines, Least squares support vector machines, Gaussian functions, k-Nearest neighbor, Probabilistic outputs",['2008'],['35'],['3'],564-568
8,Intra-sentence segmentation based on support vector machines in English–Korean machine translation systems,"This work is about intra-sentence segmentation performed before syntactic analysis of long sentences composed of at least 20 words in an English–Korean machine translation system. A long sentence has been known to spend enormous computational time and space when it is analyzed syntactically. It can also produce poor translation results. To resolve this problem, we partitioned a long sentence into a few segments to analyze each segment separately. To partition the sentence, firstly, we tried to find candidates for each segment position in the sentence. We then generated input vectors representing lexical contexts of the corresponding candidates and also used the support vector machines (SVM) algorithm to learn and recognize the appropriate segment positions. We used three kernel functions, the linear kernel, the polynomial kernel and the Gaussian kernel, to find optimal hyperplanes classifying proper positions and we compared results obtained from each kernel function. As a result of the experiments, we acquired 0.81, 0.83, and 0.79 f-measure values from the linear, polynomial and Gaussian kernel, respectively.",https://www.sciencedirect.com/science/article/pii/S0957417407001595,"Yu-Seop Kim, Yu-Jin Oh, ","Intra-sentence segmentation, Support vector machines, Linear kernel, Polynomial kernel, Gaussian kernel",['2008'],['34'],['4'],2673-2682
9,Wavelet support vector machine for induction machine fault diagnosis based on transient current signal,"This paper presents establishing intelligent system for faults detection and classification of induction motor using wavelet support vector machine (W-SVM). Support vector machines (SVM) is well known as intelligent classifier with strong generalization ability. Application of nonlinear SVM using kernel function is widely used for multi-class classification procedure. In this paper, building kernel function using wavelet will be introduced and applied for SVM multi-class classifier. Moreover, the feature vectors for training classification routine are obtained from transient current signal that preprocessed by discrete wavelet transform. In this work, principal component analysis (PCA) and kernel PCA are performed to reduce the dimension of features and to extract the useful features for classification process. Hence, a relatively new intelligent faults detection and classification method called W-SVM is established. This method is used to induction motor for faults classification based on transient current signal. The results show that the performance of classification has high accuracy based on experimental work.",https://www.sciencedirect.com/science/article/pii/S0957417407002278,"Achmad Widodo, Bo-Suk Yang, ","Wavelet support vector machines, Fault diagnosis, Transient current signal, Component analysis, Induction motor",['2008'],['35'],"['1', '2']",307-316
10,A hybrid wavelet analysis and support vector machines in forecasting development of manufacturing,"This paper proposes a hybrid methodology that exploits strengths of wavelet analysis and support vector machine model in forecasting time series, and deals with the application of proposed methodology in manufacturing time series forecasting. This method is characteristic of the preprocessing of sample data using wavelet transformation for forecast, i.e., the data sequence of evolvement of share of some sectors in manufacturing is first mapped into several time-frequency domains, and then a support vector machine is established for each domain. The final forecasting results are the algebraic sums of all the forecasted components obtained by respective support vector machine models corresponding to different time-frequency domains. Nevertheless, one of disadvantages of the method is dilemma of selection of values of parameters in support vector machine because the way of selecting values for the parameters will affect the generalization performance remarkably. In this paper, chaos optimization is applied to accomplish selection of values of parameters. Results of experiments based on gross values of textile product in Japan suggest that this hybrid method can both achieve higher accuracy in manufacturing forecasting.",https://www.sciencedirect.com/science/article/pii/S0957417407002606,"Xuesong Guo, Linyan Sun, Gang Li, Song Wang, ","Support vector machine, Chaos optimization, Forecast, Manufacturing",['2008'],['35'],"['1', '2']",415-422
11,Support vector machine-based multi-source multi-attribute information integration for situation assessment,"Understanding any given situation requires integrating many pieces of information. Such information has in most cases multiple attributes and is obtained from multiple data sources within multiple time slots. Situation assessors’ experience and preference will naturally influence the result of information integration, and hence influence the awareness generated for a situation. This study focuses on how multi-source multi-attribute information about a situation is integrated and how the awareness information for the situation is derived. A learning-based information integration approach, which embeds the fuzzy least squares support vector machine (FLS-SVM) technique, is developed in this study. This approach can assess a situation through integrating and inference obtained information and analyzing related data sources. A series of experiments show that the proposed approach has an accuracy learning ability from assessors’ experience in the information integration for generating awareness for a situation.",https://www.sciencedirect.com/science/article/pii/S0957417407000115,"Jie Lu, Xiaowei Yang, Guangquan Zhang, ","Information integration, Situation assessment, Situation awareness, Support vector machine (SVM), Information prediction",['2008'],['34'],['2'],1333-1340
12,Evaluation of ANN and SVM classifiers as predictors to the diagnosis of students with learning disabilities,"Due to the implicit characteristics of learning disabilities (LD), the identification or diagnosis of students with learning disabilities has long been a difficult issue. The LD diagnosis procedure usually involves interpreting some standard tests or checklist scores and comparing them to norms that are derived from statistical method. In this paper, we apply two well-known artificial intelligence techniques, artificial neural network (ANN) and support vector machine (SVM), to the LD diagnosis problem. To improve the overall identification accuracy, we also experiment with GA-based feature selection algorithms as the pre-processing step. To the best of our knowledge, this is the first attempt in applying ANN or SVM to similar application. The experimental results show that ANN in general performs better than SVM in this application, and the wrapper-based GA feature selection procedure can improve the LD identification accuracy, and among all, the combination of using SVM learner in the feature selection procedure and ANN learner in the classification stage results in feature set that achieves the best prediction accuracy. Most important of all, the study indicates that the ANN classifier can correctly identify up to 50% of the LD students with 100% confidence, which is much better than currently used LD diagnosis predictors derived through the statistical method. Consequently, a properly trained ANN classification model can be a strong predictor for use in the LD diagnosis procedure. Furthermore, a well-trained ANN model can also be used to verify whether a LD diagnosis procedure is adequate. In conclusion, we expect that AI techniques like ANN or SVM will certainly play an essential role in future LD diagnosis applications.",https://www.sciencedirect.com/science/article/pii/S0957417407000619,"Tung-Kuang Wu, Shian-Chang Huang, Ying-Ru Meng, ","Learning disabilities, Diagnosis, Artificial neural networks, Support vector machine, Feature selection",['2008'],['34'],['3'],1846-1856
13,Regression via Classification applied on software defect estimation,"In this paper we apply Regression via Classification (RvC) to the problem of estimating the number of software defects. This approach apart from a certain number of faults, it also outputs an associated interval of values, within which this estimate lies with a certain confidence. RvC also allows the production of comprehensible models of software defects exploiting symbolic learning algorithms. To evaluate this approach we perform an extensive comparative experimental study of the effectiveness of several machine learning algorithms in two software data sets. RvC manages to get better regression error than the standard regression approaches on both datasets.",https://www.sciencedirect.com/science/article/pii/S0957417407000875,"S. Bibi, G. Tsoumakas, I. Stamelos, I. Vlahavas, ","Software quality, Software metrics, Software fault estimation, Regression via Classification, ISBSG data set, Machine learning",['2008'],['34'],['3'],2091-2101
14,Particle swarm optimization for parameter determination and feature selection of support vector machines,"Support vector machine (SVM) is a popular pattern classification method with many diverse applications. Kernel parameter setting in the SVM training procedure, along with the feature selection, significantly influences the classification accuracy. This study simultaneously determines the parameter values while discovering a subset of features, without reducing SVM classification accuracy. A particle swarm optimization (PSO) based approach for parameter determination and feature selection of the SVM, termed PSO + SVM, is developed.Several public datasets are employed to calculate the classification accuracy rate in order to evaluate the developed PSO + SVM approach. The developed approach was compared with grid search, which is a conventional method of searching parameter values, and other approaches. Experimental results demonstrate that the classification accuracy rates of the developed approach surpass those of grid search and many other approaches, and that the developed PSO + SVM approach has a similar result to GA + SVM. Therefore, the PSO + SVM approach is valuable for parameter determination and feature selection in an SVM.",https://www.sciencedirect.com/science/article/pii/S0957417407003752,"Shih-Wei Lin, Kuo-Ching Ying, Shih-Chieh Chen, Zne-Jung Lee, ","Particle swarm optimization, Support vector machine, Parameter determination, Feature selection",['2008'],['35'],['4'],1817-1824
15,A personalized English learning recommender system for ESL students,"This paper has developed an online personalized English learning recommender system capable of providing ESL students with reading lessons that suit their different interests and therefore increase the motivation to learn. The system, using content-based analysis, collaborative filtering, and data mining techniques, analyzes real students’ reading data and generates recommender scores, based on which to help select appropriate lessons for respective students. Its performance having been tracked over a period of one year, this recommender system has proved to be very useful in heightening ESL learners’ motivation and interest in reading.",https://www.sciencedirect.com/science/article/pii/S0957417406003198,"Mei-Hua Hsu, ","Online learning, Learning system, ESL, Data mining, Association rules, Clustering, Recommender system",['2008'],['34'],['1'],683-688
16,Power quality disturbance identification using wavelet packet energy entropy and weighted support vector machines,"In this paper, wavelet packet energy entropy and weighted support vector machines are used to automatically detect and classify power quality (PQ) disturbances. Electric power quality is an aspect of power engineering that has been with us since the inception of power systems. The types of concerned disturbances include voltage sags, swells, interruptions. Wavelet packet are utilized to denoise the digital signals, to decompose the signals and then to obtain five common features for the sampling PQ disturbance signals. A weighted support vector machine is designed and trained by 5-dimension feature space points for making a decision regarding the type of the disturbance. Simulation cases illustrate the effectiveness.",https://www.sciencedirect.com/science/article/pii/S0957417407002199,"Guo-Sheng Hu, Feng-Feng Zhu, Zhen Ren, ","Weighted support vector machines (WSVMs), Power quality, Disturbances, Classification, Wavelet packet energy entropy",['2008'],['35'],"['1', '2']",143-149
17,Multiclass support vector machines for diagnosis of erythemato-squamous diseases,"A new approach based on the implementation of multiclass support vector machine (SVM) with the error correcting output codes (ECOC) is presented for diagnosis of erythemato-squamous diseases. The recurrent neural network (RNN) and multilayer perceptron neural network (MLPNN) were also tested and benchmarked for their performance on the diagnosis of the erythemato-squamous diseases. The domain contained records of patients with known diagnosis. Given a training set of such records, the classifiers learned how to differentiate a new case in the domain. The classifiers were used to detect the six erythemato-squamous diseases when 34 features defining six disease indications were used as inputs. The purpose is to determine an optimum classification scheme for this problem. The present research demonstrated that the features well represent the erythemato-squamous diseases and the multiclass SVM and RNN trained on these features achieved high classification accuracies.",https://www.sciencedirect.com/science/article/pii/S0957417407004009,"Elif Derya Übeyli, ","Multiclass support vector machine (SVM), Error correcting output codes (ECOC), Recurrent neural network (RNN), Erythemato-squamous diseases",['2008'],['35'],['4'],1733-1740
18,Forecasting financial condition of Chinese listed companies based on support vector machine,"Due to the radical changing and specialty of Chinese capital market, it is challenging to develop a powerful financial distress prediction model. In this paper, we first analyzed the feasibility of Chinese special-treated companies as distressed sample by using statistical methods. Then we developed a prediction model based on support vector machines (SVM) for an unmatched sample of Chinese high-tech manufacture companies. The grid-search technique using 10-fold cross-validation is used to find out the best parameter value of kernel function of SVM. The experiment results show that the proposed SVM model outperforms conventional statistical methods and back-propagation neural network. In general, SVM provides a robust model with high prediction accuracy for forecasting financial distress of Chinese listed companies. It is also suggested that Chinese special-treated event adopted as cut-off line has some effect on the prediction accuracy of the models.",https://www.sciencedirect.com/science/article/pii/S0957417407002382,"Yongsheng Ding, Xinping Song, Yueming Zen, ","Forecast financial condition, Chinese listed companies, Chinese special-treated event, Support vector machines, Grid-search",['2008'],['34'],['4'],3081-3089
19,Online option price forecasting by using unscented Kalman filters and support vector machines,"This study develops a hybrid model that combines unscented Kalman filters (UKFs) and support vector machines (SVMs) to implement an online option price predictor. In the hybrid model, the UKF is used to infer latent variables and make a prediction based on the Black–Scholes formula, while the SVM is employed to model the nonlinear residuals between the actual option prices and the UKF predictions. Taking option data traded in Taiwan Futures Exchange, this study examined the forecasting accuracy of the proposed model, and found that the new hybrid model is superior to pure SVM models or hybrid neural network models in terms of three types of options. This model can help investors for reducing their risk in online trading.",https://www.sciencedirect.com/science/article/pii/S0957417407001765,"Shian-Chang Huang, ","Online forecasting, Hybrid forecasting, Unscented Kalman filter, Support vector machine, Neural network",['2008'],['34'],['4'],2819-2825
20,Case-based myopic reinforcement learning for satisfying target service level in supply chain,"In the last decade, driven by global competition in the marketplace, many companies have taken initiatives to revamp their supply chains in order to increase responsiveness to changes in the marketplace. The renovation of inventory control system is central to such an effort. However, experiences in industry have shown that the control of inventory in supply chain is not an easy task because of uncertainties inherent in customer demand. In this paper, we propose a reinforcement learning algorithm appropriate for the nonstationary inventory control problem of supply chain that has a large state space. Traditional reinforcement learning algorithms such as learning automata and Q-learning have the difficulty of slow convergence when applied to the situations with large state spaces. To resolve the problems of nonstationary customer demand and large state space, we develop a case-based myopic reinforcement learning (CMRL) algorithm. A simulation-based experiment was performed to show good performance of CMRL.",https://www.sciencedirect.com/science/article/pii/S0957417407002576,"Ick-Hyun Kwon, Chang Ouk Kim, Jin Jun, Jung Hoon Lee, ","Reinforcement learning, Case-based reasoning, Supply chain, Inventory control, Service level",['2008'],['35'],"['1', '2']",389-397
21,Fault diagnostics of roller bearing using kernel based neighborhood score multi-class support vector machine,"Roller bearing is one of the most widely used rotary elements in a rotary machine. The roller bearing’s nature of vibration reveals its condition and the features that show the nature are to be extracted through some indirect means. Statistical parameters like kurtosis, standard deviation, maximum value, etc. form a set of features, which are widely used in fault diagnostics. Finding out good features that discriminate the different fault conditions of the bearing is often a problem. Selection of good features is an important phase in pattern recognition and requires detailed domain knowledge. This paper addresses the feature selection process using decision tree and uses kernel based neighborhood score multi-class support vector machine (MSVM) for classification. The vibration signal from a piezoelectric transducer is captured for the following conditions: good bearing, bearing with inner race fault, bearing with outer race fault, and inner and outer race faults. The statistical features are extracted therefrom and classified successfully using MSVM. The results of MSVM are compared with and binary support vector machine (SVM).",https://www.sciencedirect.com/science/article/pii/S0957417407002394,"V. Sugumaran, G. R. Sabareesh, K. I. Ramachandran, ","Feature selection, Decision tree, Roller bearing, Statistical features, Multi-class support vector machine, Fault detection",['2008'],['34'],['4'],3090-3098
22,Credit risk assessment with a multistage neural network ensemble learning approach,"In this study, a multistage neural network ensemble learning model is proposed to evaluate credit risk at the measurement level. The proposed model consists of six stages. In the first stage, a bagging sampling approach is used to generate different training data subsets especially for data shortage. In the second stage, the different neural network models are created with different training subsets obtained from the previous stage. In the third stage, the generated neural network models are trained with different training datasets and accordingly the classification score and reliability value of neural classifier can be obtained. In the fourth stage, a decorrelation maximization algorithm is used to select the appropriate ensemble members. In the fifth stage, the reliability values of the selected neural network models (i.e., ensemble members) are scaled into a unit interval by logistic transformation. In the final stage, the selected neural network ensemble members are fused to obtain final classification result by means of reliability measurement. For illustration, two publicly available credit datasets are used to verify the effectiveness of the proposed multistage neural network ensemble model.",https://www.sciencedirect.com/science/article/pii/S0957417407000206,"Lean Yu, Shouyang Wang, Kin Keung Lai, ","Credit risk assessment, Neural network, Ensemble learning, Bagging, Reliability",['2008'],['34'],['2'],1434-1444
23,Web service quality control based on text mining using support vector machine,"Popular websites can see hundreds of messages posted per day. The key messages for customer service department are customer complaints, including technical problems and non-satisfactory reports. An auto mechanism to classify customer messages based on the techniques of text mining and support vector machine (SVM) is proposed in this study. The proposed mechanism can filter the messages into the complaints automatically and appropriately to enhance service department productivity and customer satisfaction. This study employs the p-control chart to control the complaining rate under the expected service quality level for the website execution. This study adopts a community website as an example. The experimental results demonstrated that namely the ability of the SVM to correctly recognize defective messages exceeded 83% with an average of 89% for the classifying mechanism, and the p-control chart was capable of reflecting unusual changes of service quality timely.",https://www.sciencedirect.com/science/article/pii/S0957417406003101,"Shuchuan Lo, ","Text mining, Classification, Support vector machine (SVM), Compensating p control chart, Web quality control",['2008'],['34'],['1'],603-610
24,Churn prediction in subscription services: An application of support vector machines while comparing two parameter-selection techniques,"CRM gains increasing importance due to intensive competition and saturated markets. With the purpose of retaining customers, academics as well as practitioners find it crucial to build a churn prediction model that is as accurate as possible. This study applies support vector machines in a newspaper subscription context in order to construct a churn model with a higher predictive performance. Moreover, a comparison is made between two parameter-selection techniques, needed to implement support vector machines. Both techniques are based on grid search and cross-validation. Afterwards, the predictive performance of both kinds of support vector machine models is benchmarked to logistic regression and random forests. Our study shows that support vector machines show good generalization performance when applied to noisy marketing data. Nevertheless, the parameter optimization procedure plays an important role in the predictive performance. We show that only when the optimal parameter-selection procedure is applied, support vector machines outperform traditional logistic regression, whereas random forests outperform both kinds of support vector machines. As a substantive contribution, an overview of the most important churn drivers is given. Unlike ample research, monetary value and frequency do not play an important role in explaining churn in this subscription-services application. Even though most important churn predictors belong to the category of variables describing the subscription, the influence of several client/company-interaction variables cannot be neglected.",https://www.sciencedirect.com/science/article/pii/S0957417406002806,"Kristof Coussement, Dirk Van den Poel, ","Data mining, Churn prediction, Subscription services, Support vector machines, Parameter-selection technique",['2008'],['34'],['1'],313-327
25,A frequency assessment expert system of piezoelectric transducers in paucity of data,"It is difficult to measure in the laboratory the operating frequency of a piezoelectric transducer that is a kind of electric equipment. Some simulation methods were developed for this frequency calculation, but were still complex to perform. With high learning accuracy, a Frequency Assessment Expert System of Piezoelectric Transducers (FAESPT) is developed in this study to assess the frequency easily. FAESPT is based on mega-fuzzification that is a method to increase the learning accuracy with fuzzy neural network for the small dataset environment. In this article, FAESPT is established and its assessment accuracy is compared with traditional neural network and neuro-fuzzy method. The results indicate that FAESPT can easy to assess the frequency of a transducer and get good learning accuracy in the environment of the paucity of data.",https://www.sciencedirect.com/science/article/pii/S0957417407001674,"Fengming M. Chang, Yeong-Chin Chen, ","FAESPT, Expert system, Mega-fuzzification, Machine learning",['2008'],['34'],['4'],2747-2753
26,Identifying the source of variance shifts in the multivariate process using neural networks and support vector machines,"Process control charts are important tools for monitoring process variation in manufacturing industries. There are many situations in which the simultaneous monitoring or control of two or more related quality characteristics is necessary. Out-of-control signals in multivariate charts may be caused by one or more variables or a combination of variables. One difficulty encountered with multivariate control charts is the interpretation of an out-of-control signal. That is, we have to determine which variable is responsible for the signal. A novel approach for identifying the source of variance shifts in the multivariate process is presented in this paper. In this study, we formulated the interpretation of out-of-control signal as a classification problem. The proposed system includes a shift detector and a classifier. The traditional generalized variance chart works as a variance shift detector. When an out-of-control signal is generated, a classifier will determine which variable is responsible for the variance shift. We consider two classifiers based on neural networks (NN) and support vector machines (SVM). We propose using subgroup data and some extracted features as predictors. The performance of the proposed system was evaluated by computing its classification accuracy. Results from simulation studies indicate that the proposed approach is a successful method in identifying the source of variance change. The results indicate that the NN-based classifier and SVM classifier have similar classification performance. An illustrative example is given to describe the applications of the proposed methods in manufacturing process control. The proposed method may facilitate the diagnosis of the out-of-control signal.",https://www.sciencedirect.com/science/article/pii/S0957417407002254,"Chuen-Sheng Cheng, Hui-Ping Cheng, ","Support vector machines, Neural networks, Multivariate control charts, Variance shifts",['2008'],['35'],"['1', '2']",198-206
27,Collaborative spam filtering with heterogeneous agents,"Spam continues to generate great interest both among academicians and practitioners. Many spam filtering techniques have made considerable progress in recent years. The predominant approaches include data mining methods and machine learning methods. Researchers have largely focused on either one of the approaches since a unified framework is still lacking. To fill the gap in the literature, this paper inherits the credit-assignment problem by proposing a collaborative learning framework that could credit or blame each selected heterogeneous technique. The results of this study indicate that the collaborative learning framework is simple and comprehensible. In addition, we found that the framework offers a principle solution to combine heterogeneous individual technique to collaborative filtering for anti-spam problems.",https://www.sciencedirect.com/science/article/pii/S0957417407003715,"Dong-Her Shih, Hsiu-Sen Chiang, Binshan Lin, ","Spam, Spam filtering, Anti-spam, Collaborative learning, Heterogeneous, Multi-agent",['2008'],['35'],['4'],1555-1566
28,A study of the contribution made by evolutionary learning on dynamic load-balancing problems in distributed computing systems,"A computer simulation model that investigated the contribution made by evolutionary learning techniques on load-balancing problems was proposed. Three parameters for controlling the load-balancing activity of a node were used. The system was tested in different distributed systems, including different processing and communication speeds as well as network structures. Our experimental results showed that the system demonstrated an effective learning capability in balancing load among different processing nodes. It also showed that each of these three parameters played an important role in contributing to load-balancing, and that the system performance increased upon increasing the number of parameter changes simultaneously. The contribution made by evolutionary learning was significant as the variety of node processing speeds increased.",https://www.sciencedirect.com/science/article/pii/S0957417406002843,"Jong-Chen Chen, Guo-Xun Liao, Jr-Sung Hsie, Cheng-Hua Liao, ","System simulation, Dynamic load-balancing, Heterogeneously distributed system, Evolutionary algorithm",['2008'],['34'],['1'],357-365
29,A two-level approach to choose the cost parameter in support vector machines☆,"A new SVM model used to calculate the optimal value of cost parameter C for particular problems of linearity non-separability of data is presented in this paper. The new SVM model is formulated in the form of one of MPEC problems with an integer objective function. A lower bound, positive number, C0 is required to provide for avoiding choosing a candidate set of C. Numerical experiments show that this model for choice of C is suitable for solving SVM problems.",https://www.sciencedirect.com/science/article/pii/S0957417407000140,"Yulin Dong, Zhonghang Xia, Zunquan Xia, ","Data mining, Support vector machine, Cost parameter, Nonlinear programming, MPEC problem",['2008'],['34'],['2'],1366-1370
30,A threshold varying bisection method for cost sensitive learning in neural networks,"We propose a bisection method for varying classification threshold value for cost sensitive neural network learning. Using simulated data and different misclassification cost asymmetries, we test the proposed threshold varying bisection method and compare it with the traditional fixed-threshold method based neural network and a probabilistic neural network. The results of our experiments illustrate that the proposed threshold varying bisection method performs better than the traditional fixed-threshold method based neural network. However, when compared to probabilistic neural network, the proposed method works well only when the misclassification cost asymmetries are low.",https://www.sciencedirect.com/science/article/pii/S095741740700022X,"Parag C. Pendharkar, ","Neural networks, Classification, Bisection method, Misclassification costs",['2008'],['34'],['2'],1456-1464
31,An empirical study of sentiment analysis for chinese documents,"Up to now, there are very few researches conducted on sentiment classification for Chinese documents. In order to remedy this deficiency, this paper presents an empirical study of sentiment categorization on Chinese documents. Four feature selection methods (MI, IG, CHI and DF) and five learning methods (centroid classifier, K-nearest neighbor, winnow classifier, Naïve Bayes and SVM) are investigated on a Chinese sentiment corpus with a size of 1021 documents. The experimental results indicate that IG performs the best for sentimental terms selection and SVM exhibits the best performance for sentiment classification. Furthermore, we found that sentiment classifiers are severely dependent on domains or topics.",https://www.sciencedirect.com/science/article/pii/S0957417407001534,"Songbo Tan, Jin Zhang, ","Sentiment analysis, Information retrieval, Machine learning",['2008'],['34'],['4'],2622-2629
32,Using expert technology to select unstable slicing machine to control wafer slicing quality via fuzzy AHP,"Silicon wafer slicing is an increasingly complex manufacturing process. This involves high purity levels, crystallographic perfection and precise mechanical tolerances, thus 12 in. wafer slicing is the most difficult in terms of semiconductor manufacturing yield. As silicon wafer slicing directly impacts production costs, semiconductor manufacturers are especially concerned with increasing and maintaining the yield, as well as identifying why yields decline. The criteria for establishing the proposed algorithm are derived from literature review and modified Delphi method in semiconductor manufacturing. The main objective of this paper is to propose a new approach within the AHP framework for tackling the uncertainty and imprecision of silicon wafer slicing evaluations during manufacturing process stages, where the decision-maker’s comparison judgments are represented as fuzzy triangular numbers. Additionally, the proposed algorithm can select the evaluation outcomes to identify the worst machine of precision. Finally, results of EWMA control chart demonstrate the feasibility of the proposed fuzzy AHP-based algorithm in effectively selecting the evaluation outcomes and evaluating the precision of the worst performing machines. So, through collect data (the quality and quantity) to judge the result by fuzzy AHP, it will the key to help the engineer can find out the manufacturing process yield quickly effectively.",https://www.sciencedirect.com/science/article/pii/S095741740700098X,"Che-Wei Chang, Cheng-Ru Wu, Huang-Chu Chen, ","Silicon wafer slicing, Modified Delphi method, Fuzzy analytical hierarchy process, EWMA control chart",['2008'],['34'],['3'],2210-2220
33,Feature selection to diagnose a business crisis by using a real GA-based support vector machine: An empirical study,"This research is aimed at establishing the diagnosis models for business crises through integrating a real-valued genetic algorithm to determine the optimum parameters and SVM to perform learning and classification on data. After finishing the training processes, the proposed GA-SVM can reach a prediction accuracy of up to 95.56% for all the tested business data. Particularly, only six influential features are included in the proposed model with intellectual capital and financial features after the 2-phase selecting process; the six features are ordinary and widely available from public business reports. The proposed GA-SVM is available for business managers to conduct self-diagnosis in order to realize whether business units are really facing a crisis.",https://www.sciencedirect.com/science/article/pii/S0957417407003375,"Liang-Hsuan Chen, Huey-Der Hsiao, ","SVM, Business crisis, GA, Intellectual capital",['2008'],['35'],['3'],1145-1155
34,"Principles component analysis, fuzzy weighting pre-processing and artificial immune recognition system based diagnostic system for diagnosis of lung cancer","Lung cancers are cancers that begin in the lungs. Other types of cancers may spread to the lungs from other organs. However, these are not lung cancers because they did not start in the lungs. It is evident that usage of machine learning methods in disease diagnosis has been increasing gradually. In this study, diagnosis of lung cancer, which is a very common and important disease, was conducted with such a machine learning system. In this study, we have detected on lung cancer using principles component analysis (PCA), fuzzy weighting pre-processing and artificial immune recognition system (AIRS). The approach system has three stages. First, dimension of lung cancer dataset that has 57 features is reduced to four features using principles component analysis. Second, a new weighting scheme based on fuzzy weighting pre-processing was utilized as a pre-processing step before the main classifier. Third, artificial immune recognition system was our used classifier. We took the lung cancer dataset used in our study from the UCI machine learning database. The obtained classification accuracy of our system was 100% and it was very promising with regard to the other classification applications in literature for this problem.",https://www.sciencedirect.com/science/article/pii/S0957417406002703,"Kemal Polat, Salih Güneş, ","Principles component analysis, Artificial immune system, AIRS, Fuzzy weighting pre-processing, Lung cancer, Medical diagnosis",['2008'],['34'],['1'],214-221
35,Multilabel text categorization based on a new linear classifier learning method and a category-sensitive refinement method,"In this paper, we present a new approach for dealing with multilabel text categorization based on a new linear classifier learning method and a category-sensitive refinement method. We use a new weighted indexing technique to construct a multilabel linear classifier. We use the degrees of similarity between categories to adjust the relevance scores of categories with respect to a testing document. The testing document can be properly classified into multiple categories by using a predefined threshold value. We also compare the performance of the proposed method with the text categorization methods based on the Reuters-21578 ModeAptè Split Text Collection. The experimental results show that the performance of the proposed method is better than the existing methods.",https://www.sciencedirect.com/science/article/pii/S0957417407000723,"Yu-Chuan Chang, Shyi-Ming Chen, Churn-Jung Liau, ","Text categorization, Text classifiers, Category-sensitive refinement method, Multilabel text categorization, Relevance scores",['2008'],['34'],['3'],1948-1953
36,A novel hybrid learning algorithm for parametric fuzzy CMAC networks and its classification applications,"This paper shows fundamentals and applications of the parametric fuzzy cerebellar model articulation controller (P-FCMAC) network. It resembles a neural structure that derived from the Albus CMAC and Takagi–Sugeno–Kang parametric fuzzy inference systems. In this paper, a novel hybrid learning which consists of self-clustering algorithm (SCA) and modified genetic algorithms (MGA) is proposed for solving the classification problems. The SCA scheme is a fast, one-pass algorithm for a dynamic estimation of the number of hypercube cells in an input data space. The clustering technique does not require prior knowledge such as the number of clusters present in a data set. The number of fuzzy hypercube cells and the adjustable parameters in P-FCMAC are designed by the MGA. The MGA uses the sequential-search based efficient generation (SSEG) method to generate an initial population to determine the most efficient mutation points. Illustrative examples were conducted to show the performance and applicability of the proposed model.",https://www.sciencedirect.com/science/article/pii/S0957417407003983,"Cheng-Jian Lin, Jia-Hong Lee, Chi-Yung Lee, ","Cerebellar model articulation controller (CMAC), Genetic algorithms, TSK-type fuzzy model, Classification, Face detection",['2008'],['35'],['4'],1711-1720
37,Feature selection for the SVM: An application to hypertension diagnosis,"A support vector machine (SVM) is a novel classifier based on the statistical learning theory. To increase the performance of classification, the approach of SVM with kernel is usually used in classification tasks. In this study, we first attempted to investigate the performance of SVM with kernel. Several kernel functions, polynomial, RBF, summation, and multiplication were employed in the SVM and the feature selection approach developed [Hermes, L., & Buhmann, J. M. (2000). Feature selection for support vector machines. In Proceedings of the international conference on pattern recognition (ICPR’00) (Vol. 2, pp. 716–719)] was utilized to determine the important features. Then, a hypertension diagnosis case was implemented and 13 anthropometrical factors related to hypertension were selected. Implementation results show that the performance of combined kernel approach is better than the single kernel approach. Compared with backpropagation neural network method, SVM based method was found to have a better performance based on two epidemiological indices such as sensitivity and specificity.",https://www.sciencedirect.com/science/article/pii/S0957417406003265,"Chao-Ton Su, Chien-Hsin Yang, ","Support vector machine, Kernel, Polynomial, RBF, Classification, Hypertension, Diagnosis",['2008'],['34'],['1'],754-763
38,A comparative study on classification of features by SVM and PSVM extracted using Morlet wavelet for fault diagnosis of spur bevel gear box,The condition of an inaccessible gear in an operating machine can be monitored using the vibration signal of the machine measured at some convenient location and further processed to unravel the significance of these signals. This paper deals with the effectiveness of wavelet-based features for fault diagnosis using support vector machines (SVM) and proximal support vector machines (PSVM). The statistical feature vectors from Morlet wavelet coefficients are classified using J48 algorithm and the predominant features were fed as input for training and testing SVM and PSVM and their relative efficiency in classifying the faults in the bevel gear box was compared.,https://www.sciencedirect.com/science/article/pii/S095741740700348X,"N. Saravanan, V. N. S. Kumar Siddabattuni, K. I. Ramachandran, ","Support vector machine, Proximal support vector machines, Bevel gear box, Morlet wavelet, Statistical features, Fault detection",['2008'],['35'],['3'],1351-1366
39,Response modeling with support vector regression,"Response modeling has become a key factor to direct marketing. In general, there are two stages in response modeling. The first stage is to identify respondents from a customer database while the second stage is to estimate purchase amounts of the respondents. This paper focuses on the second stage where a regression, not a classification, problem is solved. Recently, several non-linear models based on machine learning such as support vector machines (SVM) have been applied to response modeling. However, there is a major difficulty. A typical training dataset for response modeling is so large that modeling takes very long, or, even worse, modeling may be impossible. Therefore, sampling methods have been usually employed in practice. However a sampled dataset usually leads to lower accuracy. In this paper, we employed an ε-tube based sampling for support vector regression (SVR) which leads to better accuracy than the random sampling method.",https://www.sciencedirect.com/science/article/pii/S0957417406003964,"Dongil Kim, Hyoung-joo Lee, Sungzoon Cho, ","Response modeling, Customer relationship management, Direct marketing, Support vector machines, Regression, Pattern selection",['2008'],['34'],['2'],1102-1108
40,A hybrid financial analysis model for business failure prediction,"Accounting frauds have continuously happened all over the world. This leads to the need of predicting business failures. Statistical methods and machine learning techniques have been widely used to deal with this issue. In general, financial ratios are one of the main inputs to develop the prediction models. This paper presents a hybrid financial analysis model including static and trend analysis models to construct and train a back-propagation neural network (BPN) model. Further, the experiments employ four datasets of Taiwan enterprises which support that the proposed model not only provides a high predication rate but also outperforms other models including discriminant analysis, decision trees, and the back-propagation neural network alone.",https://www.sciencedirect.com/science/article/pii/S0957417407003211,"Shi-Ming Huang, Chih-Fong Tsai, David C. Yen, Yin-Lin Cheng, ","Artificial neural networks, Business failure prediction, Financial analysis",['2008'],['35'],['3'],1034-1040
41,Application of wrapper approach and composite classifier to the stock trend prediction,"The research on the stock market prediction has been more popular in recent years. Numerous researchers tried to predict the immediate future stock prices or indices based on technical indices with various mathematical models and machine learning techniques such as artificial neural networks (ANN), support vector machines (SVM) and ARIMA models. Although some researches in the literature exhibit satisfactory prediction achievement when the average percentage error and root mean square error are used as the performance metrics, the prediction accuracy of whether stock market goes or down is seldom analyzed. This paper employs wrapper approach to select the optimal feature subset from original feature set composed of 23 technical indices and then uses voting scheme that combines different classification algorithms to predict the trend in Korea and Taiwan stock markets. Experimental result shows that wrapper approach can achieve better performance than the commonly used feature filters, such as χ2-Statistic, Information gain, ReliefF, Symmetrical uncertainty and CFS. Moreover, the proposed voting scheme outperforms single classifier such as SVM, kth nearest neighbor, back-propagation neural network, decision tree, and logistic regression.",https://www.sciencedirect.com/science/article/pii/S0957417407001819,"Chenn-Jung Huang, Dian-Xiu Yang, Yi-Ta Chuang, ","Stock prediction, Wrapper, Voting, Feature selection, Classification",['2008'],['34'],['4'],2870-2878
42,AptaCDSS-E: A classifier ensemble-based clinical decision support system for cardiovascular disease level prediction,"Conventional clinical decision support systems are generally based on a single classifier or a simple combination of these models, showing moderate performance. In this paper, we propose a classifier ensemble-based method for supporting the diagnosis of cardiovascular disease (CVD) based on aptamer chips. This AptaCDSS-E system overcomes conventional performance limitations by utilizing ensembles of different classifiers. Recent surveys show that CVD is one of the leading causes of death and that significant life savings can be achieved if precise diagnosis can be made. For CVD diagnosis, our system combines a set of four different classifiers with ensembles. Support vector machines and neural networks are adopted as base classifiers. Decision trees and Bayesian networks are also adopted to augment the system. Four aptamer-based biochip data sets including CVD data containing 66 samples were used to train and test the system. Three other supplementary data sets are used to alleviate data insufficiency. We investigated the effectiveness of the ensemble-based system with several different aggregation approaches by comparing the results with single classifier-based models. The prediction performance of the AptaCDSS-E system was assessed with a cross-validation test. The experimental results show that our system achieves high diagnosis accuracy (>94%) and comparably small prediction difference intervals (<6%), proving its usefulness in the clinical decision process of disease diagnosis. Additionally, 10 possible biomarkers are found for further investigation.",https://www.sciencedirect.com/science/article/pii/S095741740700139X,"Jae-Hong Eom, Sung-Chun Kim, Byoung-Tak Zhang, ","Clinical decision support system (CDSS), Cardiovascular disease, Classifier ensemble, Support vector machines, Neural networks, Decision trees, Bayesian networks, Machine learning",['2008'],['34'],['4'],2465-2479
43,Utilize bootstrap in small data set learning for pilot run modeling of manufacturing systems,"If the production process, production equipment, or material changes, it becomes necessary to execute pilot runs before mass production in manufacturing systems. Using the limited data obtained from pilot runs to shorten the lead time to predict future production is this worthy of study. Although, artificial neural networks are widely utilized to extract management knowledge from acquired data, sufficient training data is the fundamental assumption. Unfortunately, this is often not achievable for pilot runs because there are few data obtained during trial stages and theoretically this means that the knowledge obtained is fragile. The purpose of this research is to utilize bootstrap to generate virtual samples to fill the information gaps of sparse data. The results of this research indicate that the prediction error rate can be significantly decreased by applying the proposed method to a very small data set.",https://www.sciencedirect.com/science/article/pii/S0957417407003338,"Tung-I Tsai, Der-Chiang Li, ","Small data set, Bootstrap, Pilot runs, Manufacturing system",['2008'],['35'],['3'],1293-1300
44,Predicting opponent’s moves in electronic negotiations using neural networks,"Electronic negotiation experiments provide a rich source of information about relationships between the negotiators, their individual actions, and the negotiation dynamics. This information can be effectively utilized by intelligent agents equipped with adaptive capabilities to learn from past negotiations and assist in selecting appropriate negotiation tactics. This paper presents an approach to modeling the negotiation process in a time-series fashion using artificial neural network. In essence, the network uses information about past offers and the current proposed offer to simulate expected counter-offers. On the basis of the model’s prediction, “what-if” analysis of counter-offers can be done with the purpose of optimizing the current offer. The neural network has been trained using the Levenberg–Marquardt algorithm with Bayesian Regularization. The simulation of the predictive model on a testing set has very good and highly significant performance. The findings suggest that machine learning techniques may find useful applications in the context of electronic negotiations. These techniques can be effectively incorporated in an intelligent agent that can sense the environment and assist negotiators by providing predictive information, and possibly automating some negotiation steps.",https://www.sciencedirect.com/science/article/pii/S0957417406004155,"Réal Carbonneau, Gregory E. Kersten, Rustam Vahidov, ","Electronic negotiations, Opponent modeling, Counter-offer prediction, Offer optimization, Neural networks",['2008'],['34'],['2'],1266-1273
45,Neighborhood classifiers,"K nearest neighbor classifier (K-NN) is widely discussed and applied in pattern recognition and machine learning, however, as a similar lazy classifier using local information for recognizing a new test, neighborhood classifier, few literatures are reported on. In this paper, we introduce neighborhood rough set model as a uniform framework to understand and implement neighborhood classifiers. This algorithm integrates attribute reduction technique with classification learning. We study the influence of the three norms on attribute reduction and classification, and compare neighborhood classifier with KNN, CART and SVM. The experimental results show that neighborhood-based feature selection algorithm is able to delete most of the redundant and irrelevant features. The classification accuracies based on neighborhood classifier is superior to K-NN, CART in original feature spaces and reduced feature subspaces, and a little weaker than SVM.",https://www.sciencedirect.com/science/article/pii/S0957417406003484,"Qinghua Hu, Daren Yu, Zongxia Xie, ","Metric space, Neighborhood, Rough set, Reduction, Classifier, Norm",['2008'],['34'],['2'],866-876
46,Using neural network ensembles for bankruptcy prediction and credit scoring,"Bankruptcy prediction and credit scoring have long been regarded as critical topics and have been studied extensively in the accounting and finance literature. Artificial intelligence and machine learning techniques have been used to solve these financial decision-making problems. The multilayer perceptron (MLP) network trained by the back-propagation learning algorithm is the mostly used technique for financial decision-making problems. In addition, it is usually superior to other traditional statistical models. Recent studies suggest combining multiple classifiers (or classifier ensembles) should be better than single classifiers. However, the performance of multiple classifiers in bankruptcy prediction and credit scoring is not fully understood. In this paper, we investigate the performance of a single classifier as the baseline classifier to compare with multiple classifiers and diversified multiple classifiers by using neural networks based on three datasets. By comparing with the single classifier as the benchmark in terms of average prediction accuracy, the multiple classifiers only perform better in one of the three datasets. The diversified multiple classifiers trained by not only different classifier parameters but also different sets of training data perform worse in all datasets. However, for the Type I and Type II errors, there is no exact winner. We suggest that it is better to consider these three classifier architectures to make the optimal financial decision.",https://www.sciencedirect.com/science/article/pii/S0957417407001558,"Chih-Fong Tsai, Jhen-Wei Wu, ","Bankruptcy prediction, Credit scoring, Neural networks, Classifier ensembles",['2008'],['34'],['4'],2639-2649
47,Computer aided medical diagnosis system based on principal component analysis and artificial immune recognition system classifier algorithm,"In this study, diagnosis of lung cancer, which is a very common and important disease, was conducted with computer aided medical diagnosis system based on principal component analysis and artificial immune recognition system. The approach system has two stages. In the first stage, dimension of lung cancer dataset that has 57 features is reduced to 4 features using principal component analysis. In the second stage, artificial immune recognition system (AIRS) was our used classifier. We took the lung cancer dataset used in our study from the UCI (from University of California, Department of Information and Computer Science) Machine Learning Database. The obtained classification accuracy of our system was 100% and it was very promising with regard to the other classification applications in literature for this problem.",https://www.sciencedirect.com/science/article/pii/S0957417406003289,"Kemal Polat, Salih Güneş, ","Lung cancer, Principal component analysis (PCA), Artificial immune system, AIRS, Medical diagnosis",['2008'],['34'],['1'],773-779
48,Prediction of pricing and hedging errors for equity linked warrants with Gaussian process models☆,"Gaussian process (GP) model is a Bayesian kernel-based learning machine. In this paper, we propose a GP model with a various mixed kernel for pricing and hedging ELWs (equity linked warrants) traded at KRX with predictive distribution. We experiment with daily market data relevant to KOSPI200 call ELWs from March 2006 to July 2006, comparing the performance of the GP model with those of various neural network (NN) models to show its effectiveness. The applied NN models contain early stopping, regularized NN, and bagging. The proposed GP model shows that its forecast capability outperforms those of the three NN models in terms of both pricing and hedging errors, thereby generating consistent results.",https://www.sciencedirect.com/science/article/pii/S0957417407002837,"Gyu-Sik Han, Jaewook Lee, ","Equity linked warrants, Gaussian processes, Derivatives, HedgingNeural networks, Neural networks",['2008'],['35'],"['1', '2']",515-523
49,An ontology-based planning system for e-course generation,"Researchers in the area of educational software have always shown great interest in the automatic synthesis of learning curricula. During the recent years, with the extensive use of metadata and the emergence of the Semantic Web, this vision is gradually turning into a reality. A number of systems for curricula synthesis have been proposed. These systems are based on strong relations defined in the metadata of learning objects, which allow them to be combined with other learning objects, in order to form a complete educational program. This article presents PASER, a system for automatically synthesizing curricula using AI Planning and Semantic Web technologies. The use of classical planning techniques allows the system to dynamically construct learning paths even from disjoint learning objects, meeting the learner’s profile, preferences, needs and abilities.",https://www.sciencedirect.com/science/article/pii/S0957417407002588,"E. Kontopoulos, D. Vrakas, F. Kokkoras, N. Bassiliades, I. Vlahavas, ","Ontology, Planning, Knowledge representation, Reasoning, Automatic curricula synthesis, E-learning, E-course",['2008'],['35'],"['1', '2']",398-406
50,Web taxonomy integration with hierarchical shrinkage algorithm and fine-grained relations,"We address the problem of integrating web taxonomies from different real Internet applications. Integrating web taxonomies is to transfer instances from a source to target taxonomy. Unlike the conventional text categorization problem, in taxonomy integration, the source taxonomy contains extra information that can be used to improve the categorization. The major existing methods can be divided in two types: those that use neighboring categories to smooth the document term vector and those that consider the semantic relationship between corresponding categories of the target and source taxonomies to facilitate categorization. In contrast to the first type of approach, which only uses a flattened hierarchy for smoothing, we apply a hierarchy shrinkage algorithm to smooth child documents by their parents. We also discuss the effect of using different hierarchical levels for smoothing. To extend the second type of approach, we extract fine-grain semantic relationships, which consider the relationships between lower-level categories. In addition, we use the cosine similarity to measure the semantic relationships, which achieves better performance than existing methods. Finally, we integrate the existing approaches and the proposed methods into one machine learning model to find the best feature configuration. The results of experiments on real Internet data demonstrate that our system outperforms standard text classifiers by about 10%.",https://www.sciencedirect.com/science/article/pii/S0957417407004551,"Chia-Wei Wu, Richard Tzong-Han Tsai, Cheng-Wei Lee, Wen-Lian Hsu, ","Web taxonomy integration, Shrinkage algorithm, Text categorization",['2008'],['35'],['4'],2123-2131
51,Design of a hybrid system for the diabetes and heart diseases,"Data can be classified according to their properties. Classification is implemented by developing a model with existing records by using sample data. One of the aims of classification is to increase the reliability of the results obtained from the data. Fuzzy and crisp values are used together in medical data. Regarding to this, a new method is presented for classification of data of a medical database in this study. Also a hybrid neural network that includes artificial neural network (ANN) and fuzzy neural network (FNN) was developed. Two real-time problem data were investigated for determining the applicability of the proposed method. The data were obtained from the University of California at Irvine (UCI) machine learning repository. The datasets are Pima Indians diabetes and Cleveland heart disease. In order to evaluate the performance of the proposed method accuracy, sensitivity and specificity performance measures that are used commonly in medical classification studies were used. The classification accuracies of these datasets were obtained by k-fold cross-validation. The proposed method achieved accuracy values 84.24% and 86.8% for Pima Indians diabetes dataset and Cleveland heart disease dataset, respectively. It has been observed that these results are one of the best results compared with results obtained from related previous studies and reported in the UCI web sites.",https://www.sciencedirect.com/science/article/pii/S0957417407002126,"Humar Kahramanli, Novruz Allahverdi, ","Classification, Backpropagation, Fuzzy neural network, Pima Indians diabetes, Cleveland heart disease, k-fold cross-validation",['2008'],['35'],"['1', '2']",82-89
52,A reinforcement agent for object segmentation in ultrasound images,"The principal contribution of this work is to design a general framework for an intelligent system to extract one object of interest from ultrasound images. This system is based on reinforcement learning. The input image is divided into several sub-images, and the proposed system finds the appropriate local values for each of them so that it can extract the object of interest. The agent uses some images and their ground-truth (manually segmented) version to learn from. A reward function is employed to measure the similarities between the output and the manually segmented images, and to provide feedback to the agent. The information obtained can be used as valuable knowledge stored in the Q-matrix. The agent can then use this knowledge for new input images. The experimental results for prostate segmentation in trans-rectal ultrasound images show high potential of this approach in the field of ultrasound image segmentation.",https://www.sciencedirect.com/science/article/pii/S0957417407002904,"Farhang Sahba, Hamid R. Tizhoosh, Magdy M. M. A. Salama, ","Reinforcement learning, Image segmentation, Ultrasound imaging",['2008'],['35'],['3'],772-780
53,Increasing classification efficiency with multiple mirror classifiers,"Reducing the computational load for training and classification procedures is a major problem in many pattern recognition approaches, such as artificial neural networks and support vector machines. Combining the multiple mirror classifiers is proven to be an efficient way to reduce the classification time. In this paper, we propose an approach that uses cooperative clustering method to construct mirror classifiers. With this procedure, the set of mirror point pairs with pre-determined size near the boundary of two classes is determined. Each mirror point pair constructs a small classifier. The minimum squared error based method and support vector machine based method are proposed to determine the weights for combining the multiple mirror classifiers. Experiments show that the training efficiency and classification efficiency are improved with a slight impact on generalization performance.",https://www.sciencedirect.com/science/article/pii/S0957417407003843,"Shaomin Mu, Shengfeng Tian, Chuanhuan Yin, ","Pattern classification, Multiple classifier system, Support vector machine, Artificial neural network, Clustering methods",['2008'],['35'],['4'],1883-1888
54,Generalized Needleman–Wunsch algorithm for the recognition of T-cell epitopes,"In this paper, we propose a new encoding technique that combines the different physicochemical properties of amino acids together with Needleman–Wunsch algorithm. The algorithm was tested in the recognition of T-cell epitopes. A series of SVM classifiers, where each SVM is trained using a different physicochemical property, combined with the “max rule” enables us to obtain an improvement over the state-of-the-art approaches.",https://www.sciencedirect.com/science/article/pii/S0957417407003624,"Loris Nanni, Alessandra Lumini, ","T-cell epitopes, Machine learning, Ensemble of classifiers",['2008'],['35'],['3'],1463-1467
55,A case study: The prediction of Taiwan’s export of polyester fiber using small-data-set learning methods,"During the past four decades, the textile industry has been the industry earning the largest amount of foreign exchange in Taiwan. Notably, polyester fibers are one of the most outstanding industries in Taiwan on the global economic stage. The productivity of the polyester fiber industry in Taiwan has remained steady since the 1980s, and the midstream and downstream industry is also tied in with this development. However, starting from 2000, Taiwan’s export of polyester fibers has changed dramatically owing to the rapid economic rise of China. Since this sudden change occurred only 5 years ago, it is hard for researchers to predict the amount of future exports accurately using the trends of historical data over the past 20 years. This research adopts the methodology GIKDE (General Intervalized Kernel Density Estimator), which is a newly developed method for small-data-set prediction, to predict the amount of future exports and expects to obtain a more accurate estimation to use as a reference to help managers make plans for products, capacity and markets.",https://www.sciencedirect.com/science/article/pii/S0957417407000760,"Der-Chiang Li, Chun-Wu Yeh, Zheng-Yuan Li, ","GIKDE, Polyester fiber, Prediction, Textile industry",['2008'],['34'],['3'],1983-1994
56,A simulated-annealing-based approach for simultaneous parameter optimization and feature selection of back-propagation networks,"The back-propagation network (BPN) can be used in various fields. Nevertheless, different problems may require different parameter settings for network architectures. Rule of thumb or “trial and error” methods are usually used to determine them. However, these methods may lead worse parameter settings for network architectures. On the other hand, although a dataset may contain many features, not all features are beneficial for classification in BPN. Therefore, a simulated-annealing-based approach, denoted as SA + BPN, is proposed to obtain the optimal parameter settings for network architectures of BPN, and to select the beneficial subset of features which result in a better classification.In order to evaluate the proposed SA + BPN approach, datasets in UCI Machine Learning Repository are used to evaluate the performance of the proposed approach. The experimental results show that the parameter settings for network architectures obtained by the proposed approach are better than those of other approaches. When the feature selection is taken into consideration, the classification accuracy rates of most datasets are increased. Therefore, the developed approach can be utilized to find out the optimal parameter settings for network architectures of BPN, and discover the useful features effectively.",https://www.sciencedirect.com/science/article/pii/S0957417407000310,"Shih-Wei Lin, Tsung-Yuan Tseng, Shuo-Yan Chou, Shih-Chieh Chen, ","Back-propagation network, Simulated-annealing, Optimization, Feature selection",['2008'],['34'],['2'],1491-1499
57,An incremental cluster-based approach to spam filtering,"As email becomes a popular means for communication over the Internet, the problem of receiving unsolicited and undesired emails, called spam or junk mails, severely arises. To filter spam from legitimate emails, automatic classification approaches using text mining techniques are proposed. This kind of approaches, however, often suffers from low recall rate due to the natures of spam, skewed class distributions and concept drift. This research is thus to propose an appropriate classification approach to alleviating the problems of skewed class distributions and drifting concepts. A cluster-based classification method, called ICBC, is developed accordingly. ICBC contains two phases. In the first phase, it clusters emails in each given class into several groups, and an equal number of features (keywords) are extracted from each group to manifest the features in the minority class. In the second phase, we capacitate ICBC with an incremental learning mechanism that can adapt itself to accommodate the changes of the environment in a fast and low-cost manner. Three experiments are conducted to evaluate the performance of ICBC. The results show that ICBC can effectively deal with the issues of skewed and changing class distributions, and its incremental learning can also reduce the cost of re-training. The feasibility of the proposed approach is thus justified.",https://www.sciencedirect.com/science/article/pii/S0957417407000279,"Wen-Feng Hsiao, Te-Min Chang, ","Email classification, Skewed class distribution, Concept drift, Incremental learning",['2008'],['34'],['3'],1599-1608
58,samap: An user-oriented adaptive system for planning tourist visits,"In this paper, we present samap, whose goal is to build a software tool to help different people visit different cities. This tool integrates modules that dynamically capture user models, determine lists of activities that can provide more utility to a user given the past experience of the system with similar users, and generates plans that can be executed by the user. This system is intended to work in portable devices (mobile phones, PDAs, etc.,) with internet connection. In this paper, we describe the architecture, the knowledge model that is shared among components using an ontology, and the three components of the tool: user module, case-based module and planning module.",https://www.sciencedirect.com/science/article/pii/S0957417406004209,"Siu-Yeung Cho, ","Planning, Machine learning, Case-based reasoning, User modelling",['2008'],['34'],['2'],1318-1332
59,Probabilistic based recursive model for adaptive processing of data structures,"One of the most popular frameworks for the adaptive processing of data structures to date, was proposed by Frasconi et al. [Frasconi, P., Gori, M., & Sperduti, A. (1998). A general framework for adaptive processing of data structures. IEEE Transactions on Neural Networks, 9(September), 768–785], who used a Backpropagation Through Structures (BPTS) algorithm [Goller, C., & Kuchler, A. (1996). Learning task-dependent distributed representations by back-propagation through structures. In Proceedings of IEEE international conference on neural networks (pp. 347–352); Tsoi, A. C. (1998). Adaptive processing of data structure: An expository overview and comments. Technical report in Faculty Informatics. Wollongong, Australia: University of Wollongong] to carry out supervised learning. This supervised model has been successfully applied to a number of learning tasks that involve complex symbolic structural patterns, such as image semantic structures, internet behavior, and chemical compounds. In this paper, we extend this model, using probabilistic estimates to acquire discriminative information from the learning patterns. Using this probabilistic estimation, smooth discriminant boundaries can be obtained through a process of clustering onto the observed input attributes. This approach enhances the ability of class discrimination techniques to recognize structural patterns. The proposed model is represented by a set of Gaussian Mixture Models (GMMs) at the hidden layer and a set of “weighted sum input to sigmoid function” models at the output layer. The proposed model’s learning framework is divided into two phases: (a) locally unsupervised learning for estimating the parameters of the GMMs and (b) globally supervised learning for fine-tuning the GMMs’ parameters and optimizing weights at the output layer. The unsupervised learning phase is formulated as a maximum likelihood problem that is solved by the expectation–maximization (EM) algorithm. The supervised learning phase is formulated as a cost minimization problem, using the least squares optimization or Levenberg–Marquardt method. The capabilities of the proposed model are evaluated in several simulation platforms. From the results of the simulations, not only does the proposed model outperform the original recursive model in terms of learning performance, but it is also significantly better at classifying and recognizing structural patterns.",https://www.sciencedirect.com/science/article/pii/S0957417407000188,"Meng-Dar Shieh, Chih-Chieh Yang, ","Adaptive processing of data structures, Probabilistic recursive model, Gaussian mixture model, Expectation–maximization algorithm, Levenberg–Marquardt algorithm",['2008'],['34'],['2'],1403-1422
60,Multiclass SVM-RFE for product form feature selection,"Various form features affect consumer preference regarding product design. It is, therefore, important that designers identify these critical form features to aid them in developing appealing products. However, the problems inherent in choosing product form features have not yet been intensively investigated. In this paper, an approach based on multiclass support vector machine recursive feature elimination (SVM-RFE) is proposed to streamline the selection of optimum product form features. First, a one-versus-one (OVO) multiclass fuzzy support vector machines (multiclass fuzzy SVM) model using a Gaussian kernel was constructed based on product samples from mobile phones. Second, an optimal training model parameter set was determined using two-step cross-validation. Finally, a multiclass SVM-RFE process was applied to select critical form features by either using overall ranking or class-specific ranking. The weight distribution of each iterative step can be used to analyze the relative importance of each of the form features. The results of our experiment show that the multiclass SVM-RFE process is not only very useful for identifying critical form features with minimum generalization errors but also can be used to select the smallest feature subset for building a prediction model with a given discrimination capability.",https://www.sciencedirect.com/science/article/pii/S0957417407003041,"Moon-Chan Kim, Chang Ouk Kim, Seong Rok Hong, Ick-Hyun Kwon, ","Feature selection, Multiclass support vector machines recursive feature elimination (SVM-RFE), Mobile phone design",['2008'],['35'],"['1', '2']",531-541
61,Forward–backward analysis of RFID-enabled supply chain using fuzzy cognitive map and genetic algorithm,"Supply chain is a non-deterministic system in which uncontrollable external states with probabilistic behaviors (e.g., machine failure rate) influence on internal states (e.g., inventory level) significantly through complex causal relationships. Thanks to Radio frequency identification (RFID) technology, real time monitoring of the states is now possible. The current research on processing RFID data is, however, limited to statistical information. The goal of this research is to mine bidirectional cause-effect knowledge from the state data. In detail, fuzzy cognitive map (FCM) model of supply chain is developed. By using genetic algorithm, the weight matrix of the FCM model is discovered with the past state data, and forward (what-if) analysis is performed. Also, when sudden change in a certain state is detected, its cause is sought from the past state data throughout backward analysis. Simulation based experiments are provided to show the performance of the proposed forward–backward analysis methodology.",https://www.sciencedirect.com/science/article/pii/S0957417407003429,"Arie Ben-David, ","RFID-enabled non-deterministic supply chain, Forward–backward analysis, Fuzzy cognitive map (FCM), Weight learning, Genetic algorithm",['2008'],['35'],['3'],1166-1176
62,Comparison of classification accuracy using Cohen’s Weighted Kappa,"Many expert systems solve classification problems. While comparing the accuracy of such classifiers, the cost of error must frequently be taken into account. In such cost-sensitive applications just using the percentage of misses as the sole meter for accuracy can be misleading. Typical examples of such problems are medical and military applications, as well as data sets with ordinal (i.e., ordered) class.A new methodology is proposed here for assessing classifiers accuracy. The approach taken is based on Cohen’s Kappa statistic. It compensates for classifications that may be due to chance. The use of Kappa is proposed as a standard meter for measuring the accuracy of all multi-valued classification problems. The use of Weighted Kappa enables to effectively deal with cost-sensitive classification. When the cost of error is unknown and can only be roughly estimated, the use of sensitivity analysis with Weighted Kappa is highly recommended.",https://www.sciencedirect.com/science/article/pii/S0957417406003435,"Jorge Díez, Juan José del Coz, Oscar Luaces, Antonio Bahamonde, ","Weighted Cohen’s Kappa, Sensitivity analysis, Cost-sensitive classification, Ordinal data sets, Expert systems, Machine learning",['2008'],['34'],['2'],825-832
63,Clustering people according to their preference criteria,"Learning preferences is a useful task in application fields such as collaborative filtering, information retrieval, adaptive assistants or analysis of sensory data provided by panels. SVMs, using preference judgments, can induce ranking functions that map objects into real numbers, in such a way that more preferable objects achieve higher values. In this paper we present a new algorithm to build clusters of people with closely related tastes, and hence people whose preference judgment sets can be merged in order to learn more reliable ranking functions. In some application fields, these clusters can be seen as market segments that demand different kinds of products. The method proposed starts representing people’s preferences in a metric space, where it is possible to define a kernel based similarity function; finally a clustering algorithm discovers significant groups with homogeneous tastes. The key point of our proposal is to use the ranking functions induced from the preference judgments of each person; we will show that those functions codify the criteria used by each person to decide her preferences. To illustrate the performance of our approach, we present two experimental cases. The first one deals with the collaborative filtering database EachMovie. The second database describes a real case of consumers of beef meat.",https://www.sciencedirect.com/science/article/pii/S0957417406004088,"Shian-Chang Huang, Tung-Kuang Wu, ","Learning preferences, Clustering, Adaptive assistants, Analysis of sensory data, Market segmentation",['2008'],['34'],['2'],1274-1284
64,Integrating GA-based time-scale feature extractions with SVMs for stock index forecasting,"By integrating genetic algorithm (GA)-based optimal time-scale feature extractions with support vector machines (SVM), this study develops a novel hybrid prediction model that operates for multiple time-scale resolutions and utilizes a flexible nonparametric regressor to predict future evolutions of various stock indices. The time series of explanatory variables are decomposed using wavelet bases, and a GA is employed to extract optimal time-scale feature subsets from decomposed features. These extracted time-scale feature subsets then serve as an input for an SVM model that performs final forecasting. Compared with neural networks, pure SVMs or traditional GARCH models, the proposed model performs best. The root-mean-squared forecasting errors are significantly reduced.",https://www.sciencedirect.com/science/article/pii/S0957417407004319,"Yi-Tung Kao, Erwie Zahara, I-Wei Kao, ","Hybrid forecasting, Support vector machine, Wavelet analysis, Genetic algorithmTime series forecasting, Time series forecasting",['2008'],['35'],['4'],2080-2088
65,A hybridized approach to data clustering,"Data clustering helps one discern the structure of and simplify the complexity of massive quantities of data. It is a common technique for statistical data analysis and is used in many fields, including machine learning, data mining, pattern recognition, image analysis, and bioinformatics, in which the distribution of information can be of any size and shape. The well-known K-means algorithm, which has been successfully applied to many practical clustering problems, suffers from several drawbacks due to its choice of initializations. A hybrid technique based on combining the K-means algorithm, Nelder–Mead simplex search, and particle swarm optimization, called K–NM–PSO, is proposed in this research. The K–NM–PSO searches for cluster centers of an arbitrary data set as does the K-means algorithm, but it can effectively and efficiently find the global optima. The new K–NM–PSO algorithm is tested on nine data sets, and its performance is compared with those of PSO, NM–PSO, K–PSO and K-means clustering. Results show that K–NM–PSO is both robust and suitable for handling data clustering.",https://www.sciencedirect.com/science/article/pii/S0957417407000528,"Kyriakos C. Chatzidimitriou, Andreas L. Symeonidis, Ioannis Kontogounis, Pericles A. Mitkas, ","Data clustering, K-means clustering, Nelder–Mead simplex search method, Particle swarm optimization",['2008'],['34'],['3'],1754-1762
66,Agent Mertacor: A robust design for dealing with uncertainty and variation in SCM environments☆,"Supply Chain Management (SCM) has recently entered a new era, where the old-fashioned static, long-term relationships between involved actors are being replaced by new, dynamic negotiating schemas, established over virtual organizations and trading marketplaces. SCM environments now operate under strict policies that all interested parties (suppliers, manufacturers, customers) have to abide by, in order to participate. And, though such dynamic markets provide greater profit potential, they also conceal greater risks, since competition is tougher and request and demand may vary significantly in the quest for maximum benefit. The need for efficient SCM actors is thus implied, actors that may handle the deluge of (either complete or incomplete) information generated, perceive variations and exploit the full potential of the environments they inhabit. In this context, we introduce Mertacor, an agent that employs robust mechanisms for dealing with all SCM facets and for trading within dynamic and competitive SCM environments. Its efficiency has been extensively tested in one of the most challenging SCM environments, the Trading Agent Competition (TAC) SCM game. This paper provides an extensive analysis of Mertacor and its main architectural primitives, provides an overview of the TAC SCM environment, and thoroughly discusses Mertacor’s performance.",https://www.sciencedirect.com/science/article/pii/S0957417407002710,"R. J. Oentaryo, M. Pasquier, C. Quek, ","Supply Chain Management, Machine learning, Autonomous trading agents, Electronic commerce, Agent intelligence",['2008'],['35'],['3'],591-603
67,GenSoFNN-Yager: A novel brain-inspired generic self-organizing neuro-fuzzy system realizing Yager inference,"Pattern recognition is increasingly becoming a key component of decision support systems (DSSs) in many application areas, especially when automatically extracting semantic rules from data is a chief concern. Accordingly, this paper presents a novel evolving neuro-fuzzy DSS, the generic self-organizing fuzzy neural network realizing Yager inference (GenSoFNN-Yager), that emulates the sequential learning paradigm of the hippocampus in the brain to synthesize from low-level numerical data to high-level declarative fuzzy rules. The proposed system exhibits simple and conceptually firm computational steps that correspond closely to a plausible human logical reasoning and decision-making. Experimental results on sample benchmark problems and realistic medical diagnosis applications show the potential of the proposed system as a competent DSS.",https://www.sciencedirect.com/science/article/pii/S0957417407003764,"Muh-Cherng Wu, Yang-Kang Hsu, ","Decision support system, Declarative knowledge, Hippocampus, Rule induction, Sequential learning, Neuro-fuzzy system, Yager inference scheme",['2008'],['35'],['4'],1825-1840
68,Design of BOM configuration for reducing spare parts logistic costs,"This paper proposes an approach to reduce the total operational cost of a spare part logistic system by appropriately designing the BOM (bill of material) configuration. A spare part may have several vendors. Parts supplied by different vendors may vary in failure rates and prices – the higher the failure rate, the lower the price. Selecting vendors for spare parts is therefore a trade-off decision. Consider a machine where the BOM is composed of s critical parts and each part has k vendors. The number of possible BOM configurations for the machine is then ks. For each BOM configuration, we can use OPUS10 (proprietary software) to calculate an optimum inventory policy and its associated total logistic cost. Exhaustively searching the solution space by OPUS10 can yield an optimal BOM configuration; however, it may be formidably time-consuming. To remedy the time-consuming problem, this research proposes a GA-neural network approach to solve the BOM configuration design problem. A neural network is developed to efficiently emulate the function of OPUS10 and a GA (genetic algorithm) is developed to quickly find a near-optimal BOM configuration. Experiment results indicate that the approach can obtain an effective BOM configuration efficiently.",https://www.sciencedirect.com/science/article/pii/S0957417407001340,"Alexandros Batzios, Christos Dimou, Andreas L. Symeonidis, Pericles A. Mitkas, ","Bill of material, Spare parts, Stocking policy, Genetic algorithm, Neural network",['2008'],['34'],['4'],2417-2423
69,A neural network evaluation model for ERP performance from SCM perspective to enhance enterprise competitive advantage,"Due to increasing global competition, many enterprises are aware of the benefits of Enterprise Resource Planning (ERP). While the external environments and alliance partnerships facing an enterprise are becoming more complex, executives should consider appropriate partners to enhance efficiency and performance of supply chain management (SCM) as well as to gain potential competitive advantages. This study constructs a conceptual model to evaluate the performance and competitive advantages associated with ERP from a SCM perspective. The resulting model can be used to assist an enterprise in evaluating the potential partnerships. The survey data was gathered from a transnational textile firm in Taiwan. The training and learning models were based on the strategic thrust theory and used the Back-Propagation Network (BPN) as an evaluation tool.",https://www.sciencedirect.com/science/article/pii/S0957417407003740,"Cetin Elmas, Oguz Ustun, Hasan H. Sayan, ","Enterprise Resource Planning (ERP), Supply chain management (SCM), Strategic thrust theory, Back-Propagation Network (BPN)",['2008'],['35'],['4'],1809-1816
70,BioCrawler: An intelligent crawler for the semantic web,"Web crawling has become an important aspect of web search, as the WWW keeps getting bigger and search engines strive to index the most important and up to date content. Many experimental approaches exist, but few actually try to model the current behaviour of search engines, which is to crawl and refresh the sites they deem as important, much more frequently than others. BioCrawler mirrors this behaviour on the semantic web, by applying the learning strategies adopted in previous work on ecosystem simulation, called BioTope. BioCrawler employs the principles of BioTope’s intelligent agents on the semantic web, learns which sites are rich in semantic content and which sites link to them and adjusts its crawling habits accordingly. In the end, it learns to behave much like the state of the art search engine crawlers do. However, BioCrawler reaches that behavior solely by exploiting on-page factors, rather than off-page factors, such as the currently used link popularity.",https://www.sciencedirect.com/science/article/pii/S0957417407002990,"Bao Rong Chang, Hsiu Fen Tsai, ","Web crawling, Focused crawling, Multi-agent system, Semantic web",['2008'],['35'],"['1', '2']",524-530
71,A neuro-fuzzy controller for speed control of a permanent magnet synchronous motor drive,This paper introduces a neuro-fuzzy controller (NFC) for the speed control of a PMSM. A four layer neural network (NN) is used to adjust input and output parameters of membership functions in a fuzzy logic controller (FLC). The back propagation learning algorithm is used for training this network. The performance of the proposed controller is verified by both simulations and experiments. The hardware implementation of the controllers is made using a TMS320F240 DSP. The results are compared with the results obtain from a Proportional + Integral (PI) controller. Simulation and experimental results indicate that the proposed NFC is reliable and effective for the speed control of the PMSM over a wide range of operations of the PMSM drive.,https://www.sciencedirect.com/science/article/pii/S0957417406003162,"Burcu Erkmen, Tülay Yıldırım, ","Fuzzy logic control, Neural networks, Permanent magnet synchronous motor drive",['2008'],['34'],['1'],657-664
72,Forecast approach using neural network adaptation to support vector regression grey model and generalized auto-regressive conditional heteroscedasticity,"In order to reduce the volatility clustering effect that deteriorate the efficiency and effectiveness of time series prediction and gives rise to large residual errors, a composite method, which is SVRGM/GARCH model with neural network adaptation, is introduced to improve the predictive accuracy of the complex time series, e.g. stocks price index or futures trading index. A support vector regression (SVR) is employed to improve the control and environment parameters of grey model (GM) denoted by SVRGM. Thus, SVR learning functions to highly reduce the overshoot effect when GM is applied to time series prediction. Moreover, a generalized auto-regressive conditional heteroscedasticity (GARCH) is utilized to resolve the problem of volatility clustering in time series so as to best fit the model. Incorporating GARCH model into SVRGM prediction is scheming to effectively and efficiently tackle two crucial problems, the overshoot and volatility clustering effects, simultaneously. This composite system is adapted optimally by back-propagation neural network (BPNN).",https://www.sciencedirect.com/science/article/pii/S095741740600354X,"Murat Caner, Nurettin Umurkan, Sezai Tokat, Seydi Vakkas Üstün, ","Support vector regression, Grey model, Generalized auto-regressive conditional heteroscedasticity, Back-propagation neural network",['2008'],['34'],['2'],925-934
73,Improving classification performance of sonar targets by applying general regression neural network with PCA,"The remote detection of undersea mines in shallow waters using active sonar is a crucial subject required to maintain the security of important harbors and cost line areas. The discrimination sonar returns from mines and returns from rocks on the sea floor by human experts is usually difficult and very heavy workload. Neural network classifiers have been widely used in classification of complex sonar signals due to its adaptive and parallel processing ability. In this paper, due to the advantages on fast learning and convergence to the optimal regression surface as the number of samples becomes very large, general regression neural network (GRNN) has been used to solve the problem of classification underwater targets. Principal component analysis (PCA) has been established as a feature extraction method to improve classification performance. Receiver operating characteristic (ROC) analysis has been applied to the neural classifier to evaluate the sensitivity and specificity of diagnostic procedures.",https://www.sciencedirect.com/science/article/pii/S0957417407002667,"Yu Qian, Liang Xu, Xiuxi Li, Li Lin, Andrzej Kraslawski, ","Sonar target classification, General regression neural networks, Principal component analysis, Receiver operating characteristic",['2008'],['35'],"['1', '2']",472-475
74,Determination of optimal hierarchical fuzzy controller parameters according to loading condition with ANN,This paper represents an artificial neural network (ANN) backpropagation algorithm is used to choose best coefficients of hierarchical fuzzy power system stabilizer (HFPSS). PSS is used for stability enhancement of a single machine infinite bus (SMIB) power system. ANN algorithm is used to predict load condition of the power system. And according to the predicted load condition ANN determinates choosing optimal parameters of the hierarchical fuzzy controller (HFC) to achieve better performance. Simulation results are compared with conventional PSS (CPSS) to show the effectiveness of the proposed controller. Also quantitative criterias of measuring performance is computed for 16 loading conditions.,https://www.sciencedirect.com/science/article/pii/S095741740700156X,"Azam Beg, P. W. Chandana Prasad, Ajmal Beg, ","Excitation control, Power system stabilizer, Hierarchical fuzzy control",['2008'],['34'],['4'],2650-2655
75,LUBRES: An expert system development and implementation for real-time fault diagnosis of a lubricating oil refining process,"An expert system LUBRES (LUBricating oil Refining Expert System) is introduced in this paper. It helps plant operators in monitoring and diagnosing of abnormal situations in refining process of lubricating oil. The LUBRES structure, the knowledge base, and the inference machine are presented in detail. A new strategy is proposed for conflicts resolution – the sorting strategy of antecedents, and a selection strategy of knowledge rules in the memory knowledge base. Knowledge acquisition mechanism is based on an empirical knowledge table, while knowledge verification is carried out based on the directed graph approach. C++Builder and SQL Server 2000 have been used in developing the proposed system. LUBRES has been successfully implemented in Microsoft Windows Server environment. For 1 year, LUBRES has been used for monitoring and diagnosing of refining process of the lubricating oil. The industrial application of LUBRES proved its high reliability and accuracy.",https://www.sciencedirect.com/science/article/pii/S0957417407004186,"Hyeon Kang, Euiho Suh, Keedong Yoo, ","Fault diagnosis, Expert system, Knowledge representation, Sorting strategy, Directed graph",['2008'],['35'],['3'],1252-1266
76,Applicability of feed-forward and recurrent neural networks to Boolean function complexity modeling,"In this paper, we present the feed-forward neural network (FFNN) and recurrent neural network (RNN) models for predicting Boolean function complexity (BFC). In order to acquire the training data for the neural networks (NNs), we conducted experiments for a large number of randomly generated single output Boolean functions (BFs) and derived the simulated graphs for number of min-terms against the BFC for different number of variables. For NN model (NNM) development, we looked at three data transformation techniques for pre-processing the NN-training and validation data. The trained NNMs are used for complexity estimation for the Boolean logic expressions with a given number of variables and sum of products (SOP) terms. Both FFNNs and RNNs were evaluated against the ISCAS benchmark results. Our FFNNs and RNNs were able to predict the BFC with correlations of 0.811 and 0.629 with the benchmark results, respectively.",https://www.sciencedirect.com/science/article/pii/S0957417407001364,"Mohammad Yahya H. Al-Shamri, Kamal K. Bharadwaj, ","Machine learning, Feed-forward neural network, Recurrent neural network, Bias, Biological sequence analysis, Motif, Sub-cellular localization, Pattern recognition, Classifier design",['2008'],['34'],['4'],2436-2443
77,Packet-based context aware system to determine information system user’s context,"Context awareness has been a vital field of ubiquitous computing research. Numerous methods for capturing, interring external context and providing necessary service have been developed and relevant projects have been performed. However, user’s internal context is more valuable than the external one. Thus, more searches on internal context are needed. This paper confines its research domain to the internet based information system (IS) in order to infer the internal context of user. For inferring internal context in this IS domain, one of the computer network techniques, packet sniffing technique, is utilized. This is effective and efficient in acquiring the information of the user’s demand. Also, inference algorithm which is integrated with the acquired user’s information is proposed. Furthermore, this paper demonstrates that the prototype system adopts the suggested technique and algorithm in order to prove its validity. The proposed prototype system is the basis of providing IS user with ubiquitous services and enhances the convenience and efficiency during business hour of IS user. In this fashion, this paper presents a new pattern of context acquisition and inference in implementing the ubiquitous computing based-IS along with the direction of internal context awareness research.",https://www.sciencedirect.com/science/article/pii/S0957417407002485,"Shu-Mei Tseng, ","Context inference, Internal context, Context aware systems, Support Vector Machine, Packet capturing technique",['2008'],['35'],"['1', '2']",286-300
78,Fuzzy-genetic approach to recommender systems based on a novel hybrid user model,"The main strengths of collaborative filtering (CF), the most successful and widely used filtering technique for recommender systems, are its cross-genre or ‘outside the box’ recommendation ability and that it is completely independent of any machine-readable representation of the items being recommended. However, CF suffers from sparsity, scalability, and loss of neighbor transitivity. CF techniques are either memory-based or model-based. While the former is more accurate, its scalability compared to model-based is poor. An important contribution of this paper is a hybrid fuzzy-genetic approach to recommender systems that retains the accuracy of memory-based CF and the scalability of model-based CF. Using hybrid features, a novel user model is built that helped in achieving significant reduction in system complexity, sparsity, and made the neighbor transitivity relationship hold. The user model is employed to find a set of like-minded users within which a memory-based search is carried out. This set is much smaller than the entire set, thus improving system’s scalability. Besides our proposed approaches are scalable and compact in size, computational results reveal that they outperform the classical approach.",https://www.sciencedirect.com/science/article/pii/S095741740700351X,"Buhwan Jeong, Daewon Lee, Hyunbo Cho, Jaewook Lee, ","Recommender systems, Collaborative filtering, Web personalization, User model, Fuzzy sets",['2008'],['35'],['3'],1386-1399
79,Knowledge management system performance measure index,"For years, the evaluation of knowledge management (KM) performance has become increasingly important since it directly provides the reference for directing the strategic organization learning and, by which the capabilities are generated to match the requirement to enhance enterprise competitiveness. It implies that company has strived to manage knowledge more effectively and efficiently to improve its performance. Nevertheless, it is not yet fully understands how enterprise can successfully implement KM. In addition, despite the growing body of theory, there are relatively few KM studies which make an explicit connection between knowledge management system (KMS) and KMS itself performance. By partitioned the activities of KMS into three processes: KM strategic, the plan of KM, and implementation of KM plan, the study explores the KMS performance indicators which are useful to assess the KMS performance for firms.",https://www.sciencedirect.com/science/article/pii/S0957417406003241,"Arie Ben-David, ","Knowledge management strategic, Plan, Implementation, Performance",['2008'],['34'],['1'],734-745
80,A novel method for measuring semantic similarity for XML schema matching,"Enterprises integration has recently gained great attentions, as never before. The paper deals with an essential activity enabling seamless enterprises integration, that is, a similarity-based schema matching. To this end, we present a supervised approach to measure semantic similarity between XML schema documents, and, more importantly, address a novel approach to augment reliably labeled training data from a given few labeled samples in a semi-supervised manner. Experimental results reveal the proposed method is very cost-efficient and reliably predicts semantic similarity.",https://www.sciencedirect.com/science/article/pii/S0957417407000383,"Ali Keleş, Aytürk Keleş, ","Integrated similarity, NNPLS, Schema matching, Semantic similarity, Semi-supervised learning, XML",['2008'],['34'],['3'],1651-1658
81,Rule effectiveness in rule-based systems: A credit scoring case study,"Rule-based systems may sometimes grow very large, making their acceptance by users and their maintenance quite problematic. One therefore needs to make rule-bases as compact as possible. The classical definition of rule redundancy in the literature is based upon logic and graph theory. Another, complementary, view of redundancy is proposed here. The suggested approach is based on the contribution of individual rules to the overall system’s accuracy.It is shown here, though an analysis of a real-world credit scoring rule-based system, that by taking into account system’s accuracy, one can sometimes significantly reduce the size of a rule-base; even one which is already free from logic-related abnormalities. The approach taken here is not proposed as a substitution to classical logic and graph-based methods. Rather, it complements them.",https://www.sciencedirect.com/science/article/pii/S0957417407001728,"Gavin Potgieter, Andries P. Engelbrecht, ","Rule-based systems, Rule reduction, Verification, Validation, Classification accuracy",['2008'],['34'],['4'],2783-2788
82,ESTDD: Expert system for thyroid diseases diagnosis,"Expert or knowledge-based systems are the most common type of AIM (artificial intelligence in medicine) system in routine clinical use. They contain medical knowledge, usually about a very specifically defined task, and are able to reason with data from individual patients to come up with reasoned conclusions. Although there are many variations, the knowledge within an expert system is typically represented in the form of a set of rules.The thyroid gland is one of the most important organs in the body as thyroid hormones are responsible for controlling metabolism. As a result, thyroid function impacts on every essential organ in the body. When the thyroid produces too much hormone, the body uses energy faster than it should. This condition is called hyperthyroidism. When the thyroid does not produce enough hormone, the body uses energy slower than it should. This condition is called hypothyroidism. Thyroid disease can be difficult to diagnose because symptoms are easily confused with other conditions. When thyroid disease is caught early, treatment can control the disorder even before the onset of symptoms.This study aims at diagnosing thyroid diseases with a expert system that we called as a ESTDD (expert system for thyroid disease diagnosis). We found fuzzy rules by using neuro fuzzy method, which will be emplaced in ESTDD system. ESTDD could diagnose with 95.33% accuracy thyroid diseases. Beside it can be benefited from this system for training of students in medicine.",https://www.sciencedirect.com/science/article/pii/S0957417406002739,"María N. Moreno García, Isabel Ramos Román, Francisco J. García Peñalvo, Miguel Toro Bonilla, ","Expert system, Neuro fuzzy, Thyroid diseases",['2008'],['34'],['1'],242-246
83,Evolving model trees for mining data sets with continuous-valued classes,"This paper presents a genetic programming (GP) approach to extract symbolic rules from data sets with continuous-valued classes, called GPMCC. The GPMCC makes use of a genetic algorithm (GA) to evolve multi-variate non-linear models [Potgieter, G., & Engelbrecht, A. (2007). Genetic algorithms for the structural optimisation of learned polynomial expressions. Applied Mathematics and Computation] at the terminal nodes of the GP. Several mechanisms have been developed to optimise the GP, including a fragment pool of candidate non-linear models, k-means clustering of the training data to facilitate the use of stratified sampling methods, and specialized mutation and crossover operators to evolve structurally optimal and accurate models. It is shown that the GPMCC is insensitive to control parameter values. Experimental results show that the accuracy of the GPMCC is comparable to that of NeuroLinear and Cubist, while producing significantly less rules with less complex antecedents.",https://www.sciencedirect.com/science/article/pii/S0957417407003673,"Igor T. Podolak, ","Data mining, Continuous-valued classes, Genetic programming, Model trees",['2008'],['35'],['4'],1513-1532
84,"An association rule mining method for estimating the impact of project management policies on software quality, development time and effort","Accurate and early estimations are essential for effective decision making in software project management. Nowadays, classical estimation models are being replaced by data mining models due to their application simplicity and the rapid production of profitable results. In this work, a method for mining association rules that relate project attributes is proposed. It deals with the problem of discretizing continuous data in order to generate a manageable number of high confident association rules. The method was validated by applying it to data from a Software Project Simulator. The association model obtained allows us to estimate the influence of certain management policy factors on various software project attributes simultaneously.",https://www.sciencedirect.com/science/article/pii/S095741740600296X,"Thora Jonsdottir, Ebba Thora Hvannberg, Helgi Sigurdsson, Sven Sigurdsson, ","Association rules, Data mining, Software estimation, Project management, Simulation",['2008'],['34'],['1'],522-529
85,Decision-level fusion based on wavelet decomposition for induction motor fault diagnosis using transient current signal,"In this paper, we propose and implement a decision-level fusion model by combining the information of multi-level wavelet decomposition for fault diagnosis of induction motor using transient stator current signal. Firstly, the start-up transient current signals are collected from different faulty motors. Then signal preprocessing is conducted containing smoothing and subtracting to reduce the influence of line frequency in transient current signals. Next, we employ discrete wavelet transform technique to decompose the preprocessed signals into different frequency ranges of products, and then features are extracted from decomposed detail components. Finally, two decision-level fusion strategies, Bayesian belief fusion and multi-agent fusion, are employed. That is, fault features are classified using several classifiers and generated decisions are fused using a specific fusion algorithm. The proposed approach is evaluated by an experiment of fault diagnosis for induction motors. Experiment results show that excellent diagnosis performance can be obtained.",https://www.sciencedirect.com/science/article/pii/S0957417407003090,"T. Warren Liao, ","Fault diagnosis, Transient current signal, Discrete wavelet transform, Decision-level fusion, Induction motor",['2008'],['35'],['3'],918-928
86,Hierarchical classifier with overlapping class groups,"In this paper a novel complex classifier architecture is proposed. The architecture has a hierarchical tree-like structure with simple artificial neural networks (ANNs) at each node. The actual structure for a given problem is not preset but is built throughout training.The training algorithm’s ability to build the tree-like structure is based on the assumption that when a weak classifier (i.e., one that classifies only slightly better than a random classifier) is trained and examples from any two output classes are frequently mismatched, then they must carry similar information and constitute a sub-problem. After each ANN has been trained its incorrect classifications are analyzed and new sub-problems are formed. Consequently, new ANNs are built for each of these sub-problems and form another layer of the hierarchical classifier.An important feature of the hierarchical classifier proposed in this work is that the problem partition forms overlapping sub-problems. Thus, the classification follows not just a single path from the root, but may fork enhancing the power of the classification. It is shown how to combine the results of these individual classifiers.",https://www.sciencedirect.com/science/article/pii/S0957417406003186,"Esin Dogantekin, Mustafa Yilmaz, Akif Dogantekin, Engin Avci, Abdulkadir Sengur, ","68T05, 68T30, 68T35, Classifier neural networks",['2008'],['34'],['1'],673-682
87,The feasibility of constructing a Predictive Outcome Model for breast cancer using the tools of data mining,"A Predictive Outcome Model (POM) for breast cancer was built, and its ability to accurately predict the (5 year) outcome of an incidence of cancer was assessed. A wide range of different feature selection and classification methods were applied in order to find the best performing algorithms on a given dataset. A special Model Selection Tool, MST, was developed to facilitate the search for the most efficient classifier model. The MST includes programs for choosing different classification algorithms, selecting subsets of features, dealing with imbalance in the data and evaluating the predictive performance by various measures. These steps are important in most data mining tasks and it would be time consuming to conduct them manually. The dataset, Rose, was assembled retroactively for this study and contains data records from 257 women diagnosed with primary breast cancer in Iceland during the years 1996–1998. An extra feature, containing the risk assessment of a doctor was added to the dataset which initially contained 400 features, both to see how much that could enhance the performance of the model and to investigate to what extent such a subjective assessment can be predicted from the remaining features. The main result is that similar performance is achieved regardless of which algorithm is used. Furthermore, the inclusion of the doctor’s assessment does not appear to significantly enhance the performance. That is also reflected in the fact that the models are in general more successful in predicting the doctors risk assessment than the actual outcome if resulting Kappa values are compared.",https://www.sciencedirect.com/science/article/pii/S0957417406002594,"No authors available, ","Data mining, Feature selection, Breast cancer, Classification, Accuracy",['2008'],['34'],['1'],108-118
88,Classification of weld flaws with imbalanced class data,"This paper presents research results of our investigation of the imbalanced data problem in the classification of different types of weld flaws, a multi-class classification problem. The one-against-all scheme is adopted to carry out multi-class classification and three algorithms including minimum distance, nearest neighbors, and fuzzy nearest neighbors are employed as the classifiers. The effectiveness of 22 data preprocessing methods for dealing with imbalanced data is evaluated in terms of eight evaluation criteria to determine whether any method would emerge to dominate the others. The test results indicate that: (1) nearest neighbor classifiers outperform the minimum distance classifier; (2) some data preprocessing methods do not improve any criterion and they vary from one classifier to another; (3) the combination of using the AHC_KM data preprocessing method with the 1-NN classifier is the best because they together produce the best performance in six of eight evaluation criteria; and (4) the most difficult weld flaw type to recognize is crack.",https://www.sciencedirect.com/science/article/pii/S0957417407003223,"Ruey-Shun Chen, Duen-Kai Chen, ","Multi-class classification, One-against-all, Weld flaws, Imbalanced data, Minimum distance classifier, K nearest neighbors, Fuzzy k-nearest neighbors",['2008'],['35'],['3'],1041-1052
89,A robust technique based on invariant moments – ANFIS for recognition of human parasite eggs in microscopic images,"In this study, we propose a robust technique based on invariant moments – adaptive network based fuzzy inference system (IM-ANFIS). In this technique, some digital image processing methods such as noise reduction, contrast enhancement, segmentation, and morphological process are used for feature extraction stage of IM-ANFIS approach used in this study. Recently, the pattern recognition principles have come into prominence. The pattern recognition includes operation and design of systems that recognize patterns in data sets. Important application areas of pattern recognition techniques are character recognition, speech analysis, image segmentation, man and machine diagnostics and industrial inspection. The technique presented in this study enables to classify 16 different parasite eggs from their microscopic images. This proposed recognition method includes three stages. In first stage, a preprocessing subsystem is realized for obtaining unique features from the same group of patterns. In second stage, a feature extraction mechanism which is based on the invariant moments is used. In third stage, an adaptive network based fuzzy inference system (ANFIS) classifier is used for recognition process. We conduct computer simulations on MATLAB environment. The overall success rate is almost 95%.",https://www.sciencedirect.com/science/article/pii/S0957417407002862,"Jie Sun, Hui Li, ","Pattern recognition, Feature extraction, Invariant moments, Parasite egg recognition, Microscopic image, ANFIS",['2008'],['35'],['3'],728-738
90,Apply ontology and agent technology to construct virtual observatory,"The need to deal with abundance and heterogeneous information is apparent in the astronomy community. The virtual observatory (VO) concept is the astronomical community’s response to alleviate this problem and Web services serve as one of the most important VO enabling technologies. However, one of the limitations of Web services is the lack of semantic description of its content, thus prohibits its ability to understand the queries and its inference capabilities. This study proposes to develop a conceptual framework based on multi-agent systems and ontology technology, in order to create a VO with semantically enriched Web services. Intelligent agents represent: (1) users to submit requests (2) perform semantic matching in between users’ requests and Web services registered within agent platform, and (3) activate a serial of Web services. The capabilities offered by multi-agent systems to query and invoke semantically enriched Web Services is also exploited in this study. To validate the proposed framework, an illustration example is implemented in JADE agent platform to demonstrate how the proposed framework operates and how it benefits the research regarding to auroral images.",https://www.sciencedirect.com/science/article/pii/S0957417407000802,"Alessandra Lumini, Loris Nanni, ","Multi-agent systems, Ontology, Web services, Virtual observatory",['2008'],['34'],['3'],2019-2028
91,Listed companies’ financial distress prediction based on weighted majority voting combination of multiple classifiers,"How to effectively predict financial distress is an important problem in corporate financial management. Though much attention has been paid to financial distress prediction methods based on single classifier, its limitation of uncertainty and benefit of multiple classifier combination for financial distress prediction has also been neglected. This paper puts forward a financial distress prediction method based on weighted majority voting combination of multiple classifiers. The framework of multiple classifier combination system, model of weighted majority voting combination, basic classifiers’ voting weight model and basic classifiers’ selection principles are discussed in detail. Empirical experiment with Chinese listed companies’ real world data indicates that this method can greatly improve the average prediction accuracy and stability, and it is more suitable for financial distress prediction than single classifiers.",https://www.sciencedirect.com/science/article/pii/S0957417407002941,"Wen-Chin Chen, Pei-Hao Tai, Min-Wen Wang, Wei-Jaw Deng, Chen-Tai Chen, ","Financial distress prediction, Multiple classifier combination, Weighted majority voting",['2008'],['35'],['3'],818-827
92,Over-complete feature generation and feature selection for biometry,"In this paper a novel method for obtaining an appropriate representation of patterns is presented. The information is extracted using an over-complete global feature combination, and then the most useful features are selected by sequential forward floating selection (SFFS).This new method has been tested in two problems: trained integration of iris and face biometrics; on-line signature verification system based on global information and a one-class classifier (Parzen Window Classifier).To the best of our knowledge, this is the first work that studies and proposes a set of “artificial” features for combining biometric matchers, created starting from the scores of the matchers. We show that a classifier trained on such set of features gains a noticeable performance improvement with respect to fixed fusion rules and other trained fusion methods.Moreover, we show that an on-line signature matcher based on the “artificial” features gains a noticeable performance improvement with respect to a matcher based on the “original” global features.",https://www.sciencedirect.com/science/article/pii/S0957417407004174,"Songbo Tan, ","On-line signature, Global information, Over-complete feature combination, Feature selection, Face verification, Iris verification, Trained fusion",['2008'],['35'],['4'],2049-2055
93,A neural network-based approach for dynamic quality prediction in a plastic injection molding process,"This paper presents an innovative neural network-based quality prediction system for a plastic injection molding process. A self-organizing map plus a back-propagation neural network (SOM-BPNN) model is proposed for creating a dynamic quality predictor. Three SOM-based dynamic extraction parameters with six manufacturing process parameters and one level of product quality were dedicated to training and testing the proposed system. In addition, Taguchi’s parameter design method was also applied to enhance the neural network performance. For comparison, an additional back-propagation neural network (BPNN) model was constructed for which six process parameters were used for training and testing. The training and testing data for the two models respectively consisted of 120 and 40 samples. Experimental results showed that such a SOM-BPNN-based model can accurately predict the product quality (weight) and can likely be used for various practical applications.",https://www.sciencedirect.com/science/article/pii/S0957417407002977,"No authors available, ","Neural network-based prediction system, Injection molding process, Self-organizing map, Back-propagation neural network, Dynamic quality predictor, Taguchi’s parameter design method",['2008'],['35'],['3'],843-849
94,An improved centroid classifier for text categorization,"In the context of text categorization, Centroid Classifier has proved to be a simple and yet efficient method. However, it often suffers from the inductive bias or model misfit incurred by its assumption. In order to address this issue, we propose a novel batch-updated approach to enhance the performance of Centroid Classifier. The main idea behind this method is to take advantage of training errors to successively update the classification model by batch. The technique is simple to implement and flexible to text data. The experimental results indicate that the technique can significantly improve the performance of Centroid Classifier.",https://www.sciencedirect.com/science/article/pii/S0957417407002473,"Po-Chang Ko, Ping-Chen Lin, ","Text classification, Information retrieval, Data mining",['2008'],['35'],"['1', '2']",279-285
95,Resource allocation neural network in portfolio selection,"Portfolio selection is a resource allocation problem in a finance market. The investor’s asset optimization requires the distribution of a set of capital (resources) among a set of entities (assets) with the trade-off between risk and return. The ANN with nonlinear capability is proven to solve a large-scale complex problem effectively. It is suitable to solve NP-hard resource allocation problem. However, the traditional ANN model cannot guarantee the summation of produced investment weight always preserves 100% in output layer. This article introduces a resource allocation neural network model to optimize investment weight of portfolio. This model will dynamically adjust the investment weight as a basis of 100% of summing all of asset weights in the portfolio. The experimental results demonstrate the feasibility of optimal investment weights and superiority of ROI of buy-and-hold trading strategy compared with benchmark Taiwan Stock Exchange (TSE).",https://www.sciencedirect.com/science/article/pii/S0957417407002503,"Fadi Thabtah, Peter Cowling, ","Resource allocation, Neural network, Portfolio, Investment, Optimization",['2008'],['35'],"['1', '2']",330-337
96,Mining the data from a hyperheuristic approach using associative classification,"Associative classification is a promising classification approach that utilises association rule mining to construct accurate classification models. In this paper, we investigate the potential of associative classifiers as well as other traditional classifiers such as decision trees and rule inducers in solutions (data sets) produced by a general-purpose optimisation heuristic called the hyperheuristic for a personnel scheduling problem. The hyperheuristic requires us to decide which of several simpler search neighbourhoods to apply at each step while constructing a solutions. After experimenting 16 different solution generated by a hyperheuristic called Peckish using different classification approaches, the results indicated that associative classification approach is the most applicable approach to such kind of problems with reference to accuracy. Particularly, associative classification algorithms such as CBA, MCAR and MMAC were able to predict the selection of low-level heuristics from the data sets more accurately than C4.5, RIPPER and PART algorithms, respectively.",https://www.sciencedirect.com/science/article/pii/S0957417406003952,"Shun-Chieh Lin, Shian-Shyong Tseng, Chia-Wen Teng, ","Associative classification, Classification, Data mining, Hyperheuristic, Scheduling",['2008'],['34'],['2'],1093-1101
97,Dynamic EMCUD for knowledge acquisition,"Due to the knowledge explosion, the new objects will be evolved in a dynamic environment. Hence, the knowledge can be classified into static knowledge and dynamic knowledge. Although many knowledge acquisition methodologies, based upon the Repertory Grid technique, have been proposed to systematically elicit useful rules from static grid from domain experts, they lack the ability of grid evolution to incrementally acquire the dynamic knowledge of new evolved objects. In this paper, we propose dynamic EMCUD, a new Repertory Grid-based knowledge acquisition methodology to elicit the embedded meanings of knowledge (embedded rules bearing on m objects and k object attributes), to enhance the ability of original EMCUD to iteratively integrate new evolved objects and new added attributes into the original Acquisition Table (AT) and original Attribute Ordering Table (AOT). The AOT records the relative importance of all attribute to each object in EMCUD to capture the embedded meanings with acceptable certainty factor value by relaxing or ignoring some minor attributes. In order to discover the new evolved objects, a collaborative framework including local knowledge based systems (KBSs) and a collaborative KBS is proposed to analyze the correlations of inference behaviors of embedded rules between multiple KBSs in a dynamic environment. Each KBS monitors the frequent inference behaviors of interesting embedded rules to construct a small AT increment to facilitate the acquisition of dynamic knowledge after experts confirming the new evolved objects. Moreover, the significance of knowledge may change after a period of time, a trend of all attributes to each evolved object is used to construct a new AOT increment to help experts automatically adjust the relative importance of each attribute to each object using time series analysis approach. Besides, three cases are considered to assist experts in adjusting the certainty factor values of the dynamic knowledge of the new evolved objects from the collection of inference logs in the collaborative KBS. To evaluate the performance of dynamic EMCUD in incrementally integrating new knowledge into the knowledge base, a worm detection prototype system is implemented.",https://www.sciencedirect.com/science/article/pii/S0957417406003447,"Depei Bao, Zehong Yang, ","Knowledge acquisition, Dynamic EMCUD, Dynamic knowledge, Trend analysis, Worm detection",['2008'],['34'],['2'],833-844
98,Intelligent stock trading system by turning point confirming and probabilistic reasoning,"Financial engineering such as trading decision is an emerging research area and also has great commercial potentials. A successful stock buying/selling generally occurs near price trend turning point. Traditional technical analysis relies on some statistics (i.e. technical indicators) to predict turning point of the trend. However, these indicators can not guarantee the accuracy of prediction in chaotic domain. In this paper, we propose an intelligent financial trading system through a new approach: learn trading strategy by probabilistic model from high-level representation of time series–turning points and technical indicators. The main contributions of this paper are two-fold. First, we utilize high-level representation (turning point and technical indicators). High-level representation has several advantages such as insensitive to noise and intuitive to human being. However, it is rarely used in past research. Technical indicator is the knowledge from professional investors, which can generally characterize the market. Second, by combining high-level representation with probabilistic model, the randomness and uncertainty of chaotic system is further reduced. In this way, we achieve great results (comprehensive experiments on S&P500 components) in a chaotic domain in which the prediction is thought impossible in the past.",https://www.sciencedirect.com/science/article/pii/S0957417406003125,"Sung-Shun Weng, Hui-Ling Chang, ","Intelligent stock trading system, Turning point, Technical indicators, Markov network",['2008'],['34'],['1'],620-627
99,Using ontology network analysis for research document recommendation,"Following tremendous advancement in information technology, the speed of information development has become increasingly fast-paced. Yet the overabundance of information has forced users to spend more time and resources in searching for information relevant to their needs. Today, recommendation systems already exist that provide services like filtering, customization, and others to assist users in searching for the right information. This study proposes to use ontology and the spreading activation model for research paper recommendation, hoping that it can elevate the performance of the recommendation system and also improve the shortcomings of today’s recommendation systems. This study utilizes ontology to construct user profiles and makes use of user profile ontology as the basis to reason about the interests of users. Furthermore, this study takes advantage of the spreading activation model to search for other influential users in the community network environment, making a study on their interests in order to provide recommendation on related information. Based on actual experiment results, the method of ontology network analysis that combines ontology and the spreading activation model is effective in knowing the research interests of users. Hence, using the mechanism proposed in this study can make up for the insufficiencies or shortcomings of other recommendation systems. Moreover, the precision rate can be up to 93% showing that our recommendation system has a positive effect on the effectiveness of the recommendation.",https://www.sciencedirect.com/science/article/pii/S0957417407000620,"Yih-Chih Chiou, Chern-Sheng Lin, Bor-Cheng Chiou, ","Ontology, Ontology network analysis, Spreading activation model, Recommendation system",['2008'],['34'],['3'],1857-1869
100,The feature extraction and analysis of flaw detection and classification in BGA gold-plating areas,"In this paper, the measurements along with color image segmentation to detect all possible defects in BGA (ball grid array) type PCB (printed circuit boards) were presented. We use feature extraction and analysis as well as BPN (back-propagation neural) network classification to classify the detected defects. There are variable defects to be detected and classified including stain, scratch, solder-mask, and pinhole. The experimental results show that the proposed algorithm is successful in detecting and classifying the defects on gold-plating regions. The recognition speed becomes faster and the system becomes more flexible in comparison to the previous system. The proposed method, using unsophisticated and economical equipment, is also verified in providing highly accurate results with a low error rate.",https://www.sciencedirect.com/science/article/pii/S0957417407004101,"No authors available, ","Color image segmentation, BGA, Neural network, Flaw detection/classification",['2008'],['35'],['4'],1771-1779
101,Neural network modeling of the cellgap process for liquid crystal display fabricated on plastic substrates,"In this paper, a neural network model is presented to characterize the thickness and the uniformity of the cellgap process for flexible liquid crystal display (LCD). Input factors are explored via a D-optimal design with 15 runs and used as training data in the neural network. In order to verify the fitness of the model, three more runs are added as test data. Latin hypercube sampling and error back-propagation algorithm are used to build the model. Latin hypercube sampling is used to generate initial weights and biases of the network. The thickness of cellgap is measured at five points: one at the center and four at the edges. The average thickness is used as cellgap thickness, and the uniformity is obtained by comparing the thickness at the center and edge points.",https://www.sciencedirect.com/science/article/pii/S0957417407003351,"Paavo Kukkurainen, Pasi Luukka, ","Neural networks, Latin hypercube sampling, Flexible LCD, Cellgap",['2008'],['35'],['3'],1311-1315
102,Classification method using fuzzy level set subgrouping,"We present a new classification system which is based on fuzzy level sets subgrouping. This new classification system allows a fast classification method with quite accurate results. Classification runs were carried out with four different data sets. All four data sets were related to medical diagnostics. Data sets were related to thyroid and diabetes diagnostics, echocardiogram data relates to predicting patients chances of survival after acute heart attack. With lymphography data there are four classes to predict, normal find, metastases, malign lymph and fibrosis, from the existing data. Classification results are compared to some existing results in the literature and the results seem to compare well.",https://www.sciencedirect.com/science/article/pii/S0957417406003472,"Erdogan Kose, ","Classification, Fuzzy level set subgrouping, Ideal matrices, Medical diagnostic",['2008'],['34'],['2'],859-865
103,Modelling of colour perception of different age groups using artificial neural networks,"Colour is a subjective term which changes according to each person’s view. We should define colour physically to work with it in terms of printing or any other professional study. However, enabling the observation of colour in terms of sales and marketing and product design and development is as important as product and its packaging. The perception of colour and tendencies to colours will be different for people of different age groups and socio-economical levels. In this study, different colour samples will be shown to four different groups of primary school, university, midage and elderly people and to two different categories, namely men and women. The aim of the study is to determine which colour is more perceived and adopted by which group and which category using artificial neural network (ANN). In the direction of these determinations it has been studied with graphical and statistical illustrations how different age groups prefer colours, how much they are able to recognise primary and secondary colours and to what extent they are able to perceive them correctly.",https://www.sciencedirect.com/science/article/pii/S0957417407000917,"No authors available, ","Colour, Colour perception, Artificial neural network",['2008'],['34'],['3'],2129-2139
104,NEFCLASS based extraction of fuzzy rules and classification of risks of low back disorders,"In spite of the advanced technology, manual material handling tasks are done frequently and the incidence rate of low back disorders is still high. Classification of industrial jobs related to low back disorder risks has therefore great potential to prevent injuries. In this study, industrial jobs have been classified into two categories as “low risk” and “high risk” using neuro-fuzzy classification. Neuro-fuzzy classification has obtained better results than previous studies which used the same experimental data. Furthermore, “IF-THEN” type fuzzy rules have been extracted easily from the results to analyze potential risk factors. Ergonomic interventions can be done by means of the obtained rules for future reduction in back injuries.",https://www.sciencedirect.com/science/article/pii/S095741740700440X,"Diyar Akay, M. Ali Akcayol, Mustafa Kurt, ","Low back disorders, Manual material handling, Neuro-fuzzy classification",['2008'],['35'],['4'],2107-2112
105,Swarm Intelligence applied in synthesis of hunting strategies in a three-dimensional environment,"Systems of distributed artificial intelligence can be powerful tools in a wide variety of practical applications. Its most surprising characteristic, the emergent behavior, is also the most answerable for the difficulty in projecting these systems. This work proposes a tool capable to beget individual strategies for the elements of a multi-agent system and thereof providing to the group means on obtaining wanted results, working in a coordinated and cooperative manner as well. As an application example, a problem was taken as a basis where a predators’ group must catch a prey in a three-dimensional continuous ambient. A synthesis of system strategies was implemented of which internal mechanism involves the integration between simulators by Particle Swarm Optimization algorithm (PSO), a Swarm Intelligence technique. The system had been tested in several simulation settings and it was capable to synthesize automatically successful hunting strategies, substantiating that the developed tool can provide, as long as it works with well-elaborated patterns, satisfactory solutions for problems of complex nature, of difficult resolution starting from analytical approaches.",https://www.sciencedirect.com/science/article/pii/S0957417407000772,"E. G. Castro, M. S. G. Tsuzuki, ","Optimization, Particle swarm, Simulation, Swarm intelligence, Multi-agent system, Distributed artificial intelligence, Hunt strategies, Persecution’s game",['2008'],['34'],['3'],1995-2003
106,Verification and validation of an intelligent tutorial system,"This paper presents the results of a verification and validation process for an intelligent system. The system being studied is an Intelligent Tutorial that employs fuzzy logic and multiagent systems. Software engineering techniques were used in the verification process, while the validation exploited both qualitative and quantitative techniques.",https://www.sciencedirect.com/science/article/pii/S0957417407002795,"R. M. Aguilar, V. Muñoz, M. Noda, A. Bruno, L. Moreno, ","Verification and validation, Fuzzy system, Multiagent system",['2008'],['35'],['3'],677-685
107,Implementation of call admission control scheme in next generation mobile communication networks using particle swarm optimization and fuzzy logic systems,"In the present and next generation wireless networks, cellular system remains the major method of telecommunication infrastructure. Since the characteristic of the resource constraint, call admission control is required to address the limited resource problem in wireless network. The call dropping probability and call blocking probability are the major performance metrics for quality of service (QoS) in wireless network. Many call admission control mechanisms have been proposed in the literature to decrease connection dropping probability for handoffs and new call blocking probability in cellular communications. In this paper, we proposed an adaptive call admission control and bandwidth reservation scheme using fuzzy logic control concept to reduce the forced termination probability of multimedia handoffs. Meanwhile, we adopt particle swarm optimization (PSO) technique to adjust the parameters of the membership functions in the proposed fuzzy logic systems. The simulation results show that the proposed scheme can achieve satisfactory performance when performance metrics are measured in terms of the forced termination probability for the handoffs, the call blocking probability for the new connections and bandwidth utilization.",https://www.sciencedirect.com/science/article/pii/S0957417407003570,"Chenn-Jung Huang, Yi-Ta Chuang, Dian-Xiu Yang, ","Call admission control (CAC), Bandwidth reservation, Wireless networks, Multimedia, Quality of service, Fuzzy logic, Particle swarm optimization",['2008'],['35'],['3'],1246-1251
108,The inventory management system for automobile spare parts in a central warehouse,"Because of the complex structure of spare parts supply chain, the conventional approaches, which do not consider the relationships between decision factors globally, cannot achieve the optimal performance. Therefore, this paper aims to develop an enhanced fuzzy neural network (EFNN) based decision support system for managing automobile spares inventory in a central warehouse. In this system, the EFNN is utilized for forecasting the demand for spare parts.However, without considering relevant domain knowledge, traditional neural networks are found to be suffered from the problem of low accuracy of forecasting unseen examples. Therefore, in our EFNN, the following improvement is made: First, it assigns connection weights based on the fuzzy analytic hierarchy process (AHP) method without painstakingly turning them. Second, by generating and refining activation functions according to genetic algorithm, our EFNN can provide comprehensive and accurate activation functions and fit a wider range of nonlinear models. Last, but not least, an adaptive input variable is introduced to decrease the impact of the bullwhip effect on the forecasting accuracy.The proposed system is evaluated with the real word data and experimental results indicate that our EFNN outperforms other five models in fill rate and stock cost measures.",https://www.sciencedirect.com/science/article/pii/S0957417406004015,"S. G. Li, X. Kuo, ","Neural network, Genetic algorithm, Spare part, Inventory",['2008'],['34'],['2'],1144-1153
109,DJIA stock selection assisted by neural network,"This paper presents methodologies to select equities based on soft-computing models which focus on applying fundamental analysis for equities screening. This paper compares the performance of three soft-computing models, namely multi-layer perceptrons (MLP), adaptive neuro-fuzzy inference systems (ANFIS) and general growing and pruning radial basis function (GGAP-RBF). It studies their computational time complexity; applies several benchmark matrices to compare their performance, such as generalize rate, recall rate, confusion matrices, and correlation to appreciation. This paper also suggests how equities can be picked systematically by using relative operating characteristics (ROC) curve.",https://www.sciencedirect.com/science/article/pii/S0957417407002096,"Tong-Seng Quah, ","Stock selection, Neural Network, DJIA",['2008'],['35'],"['1', '2']",50-58
110,Visualization of patent analysis for emerging technology,"Many methods have been developed to recognize those progresses of technologies, and one of them is to analyze patent information. And visualization methods are considered to be proper for representing patent information and its analysis results. However, current visualization methods for patent analysis patent maps have some drawbacks. Therefore, we propose an alternative visualization method in this paper. With colleted keywords from patent documents of a target technology field, we cluster patent documents by the k-Means algorithm. With the clustering results, we form a semantic network of keywords without respect of filing dates. And then we build up a patent map by rearranging each keyword node of the semantic network according to its earliest filing date and frequency in patent documents. Our approach contributes to establishing a patent map which considers both structured and unstructured items of a patent document. Besides, differently from previous visualization methods for patent analysis, ours is based on forming a semantic network of keywords from patent documents. And thereby it visualizes a clear overview of patent information in a more comprehensible way. And as a result of those contributions, it enables us to understand advances of emerging technologies and forecast its trend in the future.",https://www.sciencedirect.com/science/article/pii/S0957417407000577,"Young Gil Kim, Jong Hwan Suh, Sang Chan Park, ","Visualization, Patent analysis, k-Means clustering, Semantic network, Ubiquitous computing technology",['2008'],['34'],['3'],1804-1812
111,Intelligent physician segmentation and management based on KDD approach,"Health expenditures have rapidly risen to the top of the political agenda in many countries. Physicians and their actions account for most health care spending. However, very few studies have attempted more comprehensive exploration of general practitioners’ (GPs’) practice patterns segmentation. This paper seeks to bridge this gap. It facilitates the payer or stakeholder to use these GPs’ practice patterns and features to detect inappropriate or unusual behavior to overcome the growth in health expenditures. This study uses knowledge discovery in database (KDD) to segment the general practitioners’ (GPs’) profiles by carrying out clustering techniques based on the features of expenditures, and then builds health expenditure information to support decision makers in the management of various GP’s practice patterns. It draws a complete picture relating to the health expenditures characteristics of GPs’ practice patterns by reducing the attributes space to a smaller number of dimensions. Effective segmentation of GPs’ practice patterns makes it easier to detect and investigate health fraud by recognizing and quantifying the features of claims and providers.",https://www.sciencedirect.com/science/article/pii/S0957417407000747,"Chinho Lin, Chun-Mei Lin, Sheng-Tun Li, Shu-Ching Kuo, ","Health insurance, Clustering, Self-organizing maps (SOM), Knowledge discovery in database (KDD)",['2008'],['34'],['3'],1963-1973
112,Using backpropagation neural network for face recognition with 2D + 3D hybrid information,"Biometric measurements received an increasing interest for security applications in the last two decades. After the 911 terrorist attacks, face recognition has been an active research in this area. However, very few research group focus on face recognition from both 2D and 3D facial images. Almost all existing recognition systems rely on a single type of face information: 2D intensity (or color) image or 3D range data set [Wang, Y., Chua, C., & Ho, Y. (2002). Facial feature detection and face recognition from 3D and 3D images. Pattern Recognition Letters, 23, 1191–1202]. The objective of this study is to develop an effective face recognition system that extracts and combines 2D and 3D face features to improve the recognition performance. The proposed method derived the information of 3D face (disparity face) using a designed synchronous Hopfield neural network. Then, we retrieved 2D and 3D face features with principle component analysis (PCA) and local autocorrelation coefficient (LAC) respectively. Eventually, the information of features was learned and classified using backpropagation neural networks. An experiment was conducted with 100 subjects, and for each subject thirteen stereo face images were taken with different expressions. Among them, seven faces with expressions were used for training, and the rest of the expressions were used for testing. The experimental results show that the proposed method effectively improved the recognition rate by combining the 2D with 3D face information.",https://www.sciencedirect.com/science/article/pii/S0957417407002540,"Rıdvan Saraçoğlu, Kemal Tütüncü, Novruz Allahverdi, ","Stereovision, Face recognition, Principle component analysis (PCA), Local autocorrelation coefficients (LAC), Disparity face, Backpropagation neural network",['2008'],['35'],"['1', '2']",361-372
113,A new approach on search for similar documents with multiple categories using fuzzy clustering,"Searching for similar document has an important role in text mining and document management. In whether similar document search or in other text mining applications generally document classification is focused and class or category that the documents belong to is tried to be determined. The aim of the present study is the investigation of the case which includes the documents that belong to more than one category. The system used in the present study is a similar document search system that uses fuzzy clustering. The situation of belonging to more than one category for the documents is included by this system. The proposed approach consists of two stages to solve multicategories problem. The first stage is to find out the documents belonging to more than one category. The second stage is the determination of the categories to which these found documents belong to. For these two aims α-threshold Fuzzy Similarity Classification Method (α-FSCM) and Multiple Categories Vector Method (MCVM) are proposed as written order. Experimental results showed that proposed system can distinguish the documents that belong to more than one category efficiently. Regarding to the finding which documents belong to which classes, proposed system has better performance and success than the traditional approach.",https://www.sciencedirect.com/science/article/pii/S0957417407001467,"Banu Diri, Songul Albayrak, ","Text mining, Document similarity, Similarity search, Fuzzy clustering, Multiple categories",['2008'],['34'],['4'],2545-2554
114,Visualization and analysis of classifiers performance in multi-class medical data,"The primary role of the thyroid gland is to help regulation of the body’s metabolism. The correct diagnosis of thyroid dysfunctions is very important and early diagnosis is the key factor in its successful treatment. In this article, we used four different kinds of classifiers, namely Bayesian, k-NN, k-Means and 2-D SOM to classify the thyroid gland data set. The robustness of classifiers with regard to sampling variations is examined using a cross validation method and the performance of classifiers in medical diagnostic is visualized by using cobweb representation. The cobweb representation is the original contribution of this work to visualize the classifiers performance when the data have more than two classes. This representation is a newly used method to visualize the classifiers performance in medical diagnosis.",https://www.sciencedirect.com/science/article/pii/S0957417406003137,"No authors available, ","Bayesian, k-NN, k-Means, 2-D SOM, Cross validation, Confusion matrix, ROC analysis, Cobweb representation, Thyroid gland data, Medical diagnosis",['2008'],['34'],['1'],628-634
115,A new approach to intelligent fault diagnosis of rotating machinery,"This paper presents a new approach to intelligent fault diagnosis based on statistics analysis, an improved distance evaluation technique and adaptive neuro-fuzzy inference system (ANFIS). The approach consists of three stages. First, different features, including time-domain statistical characteristics, frequency-domain statistical characteristics and empirical mode decomposition (EMD) energy entropies, are extracted to acquire more fault characteristic information. Second, an improved distance evaluation technique is proposed, and with it, the most superior features are selected from the original feature set. Finally, the most superior features are fed into ANFIS to identify different abnormal cases. The proposed approach is applied to fault diagnosis of rolling element bearings, and testing results show that the proposed approach can reliably recognise different fault categories and severities. Moreover, the effectiveness of the proposed feature selection method is also demonstrated by the testing results.",https://www.sciencedirect.com/science/article/pii/S0957417407003831,"No authors available, ","Feature selection, Superior feature, Improved distance evaluation technique, Adaptive neuro-fuzzy inference system, Fault diagnosis",['2008'],['35'],['4'],1593-1600
116,Using neural networks and immune algorithms to find the optimal parameters for an IC wire bonding process,"The wire bonding process is the key process in an IC chip-package. It is an urgent problem for IC chip-package industry to improve the wire bonding process capability. In this study, an integration of artificial neural networks (ANN) with artificial immune systems (AIS) is proposed to optimize parameters for an IC wire bonding process. The algorithm of AIS with memory cell and suppressor cell mechanisms is developed. The back-propagation ANN is used to establish the nonlinear multivariate relationships between the wire boning parameters and responses. Then a Taguchi method is applied to identify the critical parameters of AIS. Finally, the AIS algorithm is applied to find the optimal parameters by using the output of ANN as the affinity measure. A comparison between the result of the proposed AIS and that of a genetic algorithm (GA) is conducted in this study. The comparison shows that the searching quality of the proposed AIS is more effective than the GA in finding the optimal wire bonding process parameters.",https://www.sciencedirect.com/science/article/pii/S0957417406002922,"Yaguo Lei, Zhengjia He, Yanyang Zi, ","Artificial immune system (AIS), Artificial neural networks (ANN), Taguchi method, Wire bonding, Genetic algorithm (GA)",['2008'],['34'],['1'],427-436
117,Incremental clustering of mixed data based on distance hierarchy,"Clustering is an important function in data mining. Its typical application includes the analysis of consumer’s materials. Adaptive resonance theory network (ART) is very popular in the unsupervised neural network. Type I adaptive resonance theory network (ART1) deals with the binary numerical data, whereas type II adaptive resonance theory network (ART2) deals with the general numerical data. Several information systems collect the mixing type attitudes, which included numeric attributes and categorical attributes. However, ART1 and ART2 do not deal with mixed data. If the categorical data attributes are transferred to the binary data format, the binary data do not reflect the similar degree. It influences the clustering quality. Therefore, this paper proposes a modified adaptive resonance theory network (M-ART) and the conceptual hierarchy tree to solve similar degrees of mixed data. This paper utilizes artificial simulation materials and collects a piece of actual data about the family income to do experiments. The results show that the M-ART algorithm can process the mixed data and has a great effect on clustering.",https://www.sciencedirect.com/science/article/pii/S0957417407003430,"Tung-Hsu (Tony) Hou, Chi-Hung Su, Hung-Zhi Chang, ","Adaptive resonance theory network, Conceptual hierarchy, Clustering algorithm, Unsupervised neural network, Data mining",['2008'],['35'],['3'],1177-1185
118,Multiprocessor system scheduling with precedence and resource constraints using an enhanced ant colony system,"This study presents and evaluates a modified ant colony optimization (ACO) approach for the precedence and resource-constrained multiprocessor scheduling problems. A modified ant colony system is proposed to solve the scheduling problems. A two-dimensional matrix is proposed in this study for assigning jobs on processors, and it has a time-dependency relation structure. The dynamic rule is designed to modify the latest starting time of jobs and hence the heuristic function. In exploration of the search solution space, this investigation proposes a delay solution generation rule to escape the local optimal solution. Simulation results demonstrate that the proposed modified ant colony system algorithm provides an effective and efficient approach for solving multiprocessor system scheduling problems with resource constraints.",https://www.sciencedirect.com/science/article/pii/S0957417407000851,"Chung-Chian Hsu, Yan-Ping Huang, ","Ant colony optimization, Scheduling, Multiprocessor",['2008'],['34'],['3'],2071-2081
119,Optimal tuning of PI coefficients by using fuzzy-genetic for V/f controlled induction motor,"This paper presents a novel speed control scheme of an induction motor using genetic-fuzzy logic. The aim of this paper is to improve a new method of the optimal tuning of proportional integral controller coefficients in the off-line control of a induction motor.The V/f control, which realizes a low cost and simple design, is advantageous in the middle to high-speed range. Its torque response depends on the electrical time constant of the motor and adjustments of the control parameters are not need. Therefore, V/f control of induction motor is carried out. Space vector pulse width modulation with V/f is used for controlling the motor. Because, it includes minimum harmonics according to the other PWM techniques. In this paper, the first step is the identification of the system via fuzzy logic, using performance value (1/(1 + maximum overshoot and settling time)) obtained from the application circuit for different Kp–Ki pairs. In the second step, the purpose is to find the optimum controller coefficients using the fuzzy model as the objective function via genetic algorithms. A digital signal processor controller (dsPIC30F6010) was used to carry out control applications. Then, the proposed method is compared with Ziegler–Nichols method.",https://www.sciencedirect.com/science/article/pii/S0957417407001637,"Shih-Tang Lo, Ruey-Maw Chen, Yueh-Min Huang, Chung-Lun Wu, ","Fuzzy, Induction motor, Genetic, DSP",['2008'],['34'],['4'],2714-2720
120,Fast blocking of undesirable web pages on client PC by discriminating URL using neural networks,"The world wide web (WWW) has become the largest information archive in the world because of its connectivity and scalability. Web pages, identified by URLs, are the basic forms for transmitting the requested information to clients’ PC, whose number continuously explodes. There are a large portion of the web pages containing undesirable content, such as pornography, crimes, drugs and terrorisms, which makes viewers’ discretion necessary. The large number of the undesirable web pages, however, has made the blocking more difficult on a client PC, because checking through the large collection of URLs is a time-consuming task. We propose a neural network method for determining the existing status of a requested URL in the large prohibited collection. The large prohibited URL collection containing 400,000 URLs was obtained by specifying a number of keywords, e.g. “porn” or “sex”, on several commercial search engines. The simulation results show superior performances in both memory requirement and speed, comparing with a database implementation on the same PC.",https://www.sciencedirect.com/science/article/pii/S095741740700036X,"Seydi Vakkas Ustun, Metin Demirtas, ","World wide web, URL, Web page content, Neural network",['2008'],['34'],['2'],1533-1540
121,An expert system based on linear discriminant analysis and adaptive neuro-fuzzy inference system to diagnosis heart valve diseases,"In the last two decades, the use of artificial intelligence methods in biomedical analysis is increasing. This is mainly because of the effectiveness of classification and detection systems have improved in a great deal to help medical experts in diagnosing. In this paper, we investigate the use of linear discriminant analysis (LDA) and adaptive neuro-fuzzy inference system (ANFIS) to determine the normal and abnormal heart valves from the Doppler heart sounds. The proposed heart valve disorder detection system is composed of three stages. The first stage is the pre-processing stage. Filtering, normalization and white-denoising are the processes that were used in this stage. The feature extraction is the second stage. During feature extraction stage, Wavelet transforms and short-time Fourier transform were used. As next step, wavelet entropy was applied to these features. For reducing the complexity of the system, LDA was used for feature reduction. In the classification stage, ANFIS classifier is chosen. To evaluate the performance of proposed methodology, a comparative study is realized by using a data set containing 215 samples. The validation of the proposed method is measured by using the sensitivity and specificity parameters. 95.9% sensitivity and 94% specificity rate was obtained.",https://www.sciencedirect.com/science/article/pii/S0957417407002291,"Heng Ma, ","Doppler heart sounds, Heart valves, Feature extraction, Wavelet decomposition, Feature reduction, Adaptive neuro-fuzzy inference system",['2008'],['35'],"['1', '2']",214-222
122,Recognition of semiconductor defect patterns using spatial filtering and spectral clustering,"Diverse defect patterns shown on the wafer map usually contain important information for quality engineers to find their root causes of abnormalities. Today, even with highly automated and precisely monitored facilities used in a near dust-free clean room and operated with well-trained process engineers, the occurrence of spatial defects still cannot be avoided. This research presents a spatial defect diagnosis system and attempts to solve two challenging problems for semiconductor manufacturing: (1) to estimate the number of clusters in advance, and (2) to separate both convex and non-convex defect clusters at the same time. In this paper, a spatial filter is used to denoise the noisy wafer map and to extract meaningful defect clusters. To isolate various types of defect patterns, a hybrid scheme combining entropy fuzzy c means (EFCM) with spectral clustering is applied to the denoised output. Furthermore, a decision tree based on two cluster features (convexity and eigenvalue ratio) is constructed to identify the specific defect type and to provide decision support for quality engineers. The proposed approach is validated with an empirical wafer bin maps obtained in a DRAM company in Taiwan. Experimental results show that four kinds of mixed-type defect patterns are successfully extracted and classified. More importantly, the proposed method is very promising to be further applied to other industries, such as liquid crystal or plasma display.",https://www.sciencedirect.com/science/article/pii/S0957417407000681,"Abdulkadir Sengur, ","Defect pattern, Spectral clustering, Fuzzy clustering, Data mining",['2008'],['34'],['3'],1914-1923
123,Particle swarm optimization for pap-smear diagnosis,"The term pap-smear refers to samples of human cells stained by the so-called Papanicolaou method. The purpose of the Papanicolaou method is to diagnose pre-cancerous cell changes before they progress to invasive carcinoma. In this paper, a metaheuristic algorithm is proposed in order to classify the cells. Two databases are used, constructed in different times by expert Medical Doctors, consisting of 917 and 500 images of pap-smear cells, respectively. Each cell is described by 20 numerical features and the cells fall into seven classes but a minimal requirement is to separate normal from abnormal cells which is a two-class problem. For finding the best possible performing feature subset, an effective particle swarm optimization scheme is proposed. This algorithmic scheme is combined with a number of nearest neighbor based classifiers. Results show that classification accuracy generally outperforms other previously applied intelligent approaches.",https://www.sciencedirect.com/science/article/pii/S0957417407003922,"Chih-Hsuan Wang, ","Particle swarm optimization, Feature selection problem, Pap-smear classification, Nearest neighbor based classifiers",['2008'],['35'],['4'],1645-1656
124,Ontological fuzzy agent for electrocardiogram application,"The electrocardiogram (ECG) signal is adopted extensively as a low-cost diagnostic procedure to provide information concerning the healthy status of the heart. However, the QRS complex must be calculated accurately before proceeding with the heart rate variability (HRV). In particular, the R peak needs to be detected reliably. This study presents an adaptive fuzzy detector to detect the R peak correctly. Additionally, an ontological fuzzy agent is presented to process the collection of ECG signals. The required knowledge is stored in the ontology, which comprises some personal ontologies and predefined by domain experts. The ontological fuzzy agent retrieves the ECG signals with R peaks marked for HRV analysis and ECG further applications. It contains a personal fuzzy filter, an HRV analysis mechanism, and a fuzzy normed inference engine. Moreover, the ECG fuzzy signal space and some important properties are presented to define the working environment of the agent. An experimental platform has been constructed to test the performance of the agent. The results indicate that the proposed method can work effectively.",https://www.sciencedirect.com/science/article/pii/S0957417407003545,"Yannis Marinakis, Magdalene Marinaki, Georgios Dounias, ","Ontology, Fuzzy inference, Agent, Electrocardiogram (ECG), Heart rate variability (HRV)",['2008'],['35'],['3'],1223-1236
125,Design of a two-stage fuzzy classification model,"This paper proposes a novel two-stage fuzzy classification model established by the fuzzy feature extraction agent (FFEA) and the fuzzy classification unit (FCU). At first, we propose a FFEA to validly extraction the feature variables from the original database. And then, the FCU, which is the main determination of the classification result, is developed to generate the if–then rules automatically. In fact, both the FFEA and FCU are fuzzy models themselves. In order to obtain better classification results, we utilize the genetic algorithms (GAs) and adaptive grade mechanism (AGM) to tune the FFEA and FCU, respectively, to improve the performance of the proposed fuzzy classification model. In this model, GAs are used to determine the distribution of the fuzzy sets for each feature variable of the FFEA, and the AGM is developed to regulate the confidence grade of the principal if–then rule of the FCU. Finally, the well-known Iris, Wine, and Glass databases are exploited to test the performances. Computer simulation results demonstrate that the proposed fuzzy classification model can provide a sufficiently high classification rate in comparison with other models in the literature.",https://www.sciencedirect.com/science/article/pii/S095741740700365X,"Chang-Shing Lee, Mei-Hui Wang, ","Fuzzy model, Classification problem, Genetic algorithmsFuzzy feature extraction agent, Fuzzy feature extraction agent, Adaptive grade mechanism",['2008'],['35'],['3'],1482-1495
126,A biomedical system based on fuzzy discrete hidden Markov model for the diagnosis of the brain diseases,"Because it is a non-invasive, easy to apply and reliable technique, transcranial doppler (TCD) study of the adult intracerebral circulation has increased enormously in the last 10 years. In this study, a biomedical system has been implemented in order to classify the TCD signals recorded from the temporal region of the brain of 82 patients as well as of 24 healthy people. The diseases were investigated cerebral aneurysm, brain hemorrhage, cerebral oedema and brain tumor. The system is composed of feature extraction and classification parts, basically. In the feature extraction stage, the linear predictive coding analysis and cepstral analysis were applied in order to extract the cepstral and delta-cepstral coefficients in frame level as feature vectors. In the classification stage, discrete hidden Markov model (DHMM) based methods were used. In order to avoid loosing information due to vector quantization and to increase the classification performance, a fuzzy approach based similarity was applied to implement the DHMM. The performance of the proposed Fuzzy DHMM (FDHMM) was compared with some methods such as DHMM, artificial neural network (ANN), neuro-fuzzy approaches and obtained better classification performance than these methods.",https://www.sciencedirect.com/science/article/pii/S0957417407003284,"Tzuu-Hseng S. Li, Nai Ren Guo, Chia Ping Cheng, ","Transcranial doppler signals, Fuzzy discrete hidden Markov model, Similarity",['2008'],['35'],['3'],1104-1114
127,ReviewExpert systems and evolutionary computing for financial investing: A review,"This innovative, experimental approach to a literature review begins with queries for finance-related articles to the Expert Systems with Applications literature database. A classification language is constructed, and retrieved articles are systematic indexed. Hypotheses are offered about the patterns in the distribution of indexed concepts. Results include that authors tended to use expert systems tools in the early 1990s but evolutionary computation tools in mid-2000s. However, the most common financial application area in both the earlier and later periods was financial accounting. One trend in the latest work is to merge both knowledge-based and evolutionary approaches. Opportunities exist to reuse the knowledge bases built for the financial accounting work for speculative investing.",https://www.sciencedirect.com/science/article/pii/S0957417407001911,"Harun Uğuz, Ali Öztürk, Rıdvan Saraçoğlu, Ahmet Arslan, ","Literature review, Finance, Expert systems, Evolutionary computing, Classification language",['2008'],['34'],['4'],2232-2240
128,An expert system to derive carryover effect for pharmaceutical sales detailing optimization,"Most pharmaceutical companies that rely heavily on their sales force for success do not fully understand the effect of details made in previous quarters have on the current quarter, which is also known as the carryover effect. This paper proposes an expert system that utilizes neural networks with nonlinear programming to accurately derive the carryover effect at the customer level. Results suggest that using this adaptive and easy-to-implement expert system helped a firm increase its sales by 3.4% while reducing its sales force expenditure by 8.9%, compared to the control group. The implications of this approach are considered.",https://www.sciencedirect.com/science/article/pii/S0957417407000516,"Roy Rada, ","Carryover effect, Expert system, Promotional response function, Neural networks, Nonlinear programming",['2008'],['34'],['3'],1742-1753
129,A frame knowledge system for managing financial decision knowledge,"Managing decision knowledge or expertise from domain experts is one of the most exciting challenges in today’s knowledge management field. The nature of decision knowledge in determining a firm’s financial health is context-dependent, intangible, and tacit in nature. Knowledge-based systems (KBS) have been recognized as a successful paradigm for managing financial decision knowledge attributed to possessing capabilities of reasoning and enhancing the consistency of decision-making. However, most present KBS adopt rules as the knowledge representation scheme, which cannot express the expert’s knowledge construct systematically when dealing with more numerous and disordered knowledge connotations. In addition, the standalone nature of the systems hinders them from deploying onto heterogeneous platforms and cannot accommodate to the emerging Web-enabled environment. To reduce these flaws, this study proposes a frame knowledge system in which the structural and procedural decision knowledge is encapsulated so that unnecessary interference can be avoided. A protocol analysis, before encapsulation, is conducted to elicit the tacit and unstructured knowledge from a senior CPA we cooperated with. The deployment and Web enabling issue is tackled by using Jess and Java interoperable computing. With these combined, it is possible to prompt the understandability, accessibility, and reusability of KBS. The effectiveness of the proposed system is validated in supporting the expert’s decision-making by conducting an empirical experimentation on 537 companies listed in the Taiwan Stock Exchange Corporation.",https://www.sciencedirect.com/science/article/pii/S0957417407003247,"John C. Yi, ","Knowledge-based system, Frame knowledge representation, Knowledge acquisition, Jess, Financial decision management",['2008'],['35'],['3'],1068-1079
130,Fuzzy consensus measure on verbal opinions,"In the group decision-making process, consensus is an important indication of group agreement or reliability. Traditional methods to measure consensus refer mostly to gauging variance among the participants’ opinions by transforming them into numbers in the interval scale. In this study we propose a new value-based measure, in which verbal opinions are transformed into values by means of fuzzy membership functions. To understand how the proposed method performs, we conduct two experiments to compare its performance with the variance-based methods and entropy measure. The results show that our method is more appropriate to account for participants’ consensus judgments based on verbal opinions.",https://www.sciencedirect.com/science/article/pii/S0957417407002965,"Weissor Shiue, Sheng-Tun Li, Kuan-Ju Chen, ","Consensus measure, Verbal opinions, Fuzzy membership functions",['2008'],['35'],['3'],836-842
131,Prediction of compressive and tensile strength of limestone via genetic programming,"Accurate determination of compressive and tensile strength of limestone is an important subject for the design of geotechnical structures. Although there are several classical approaches in the literature for strength prediction their predictive accuracy is generally not satisfactory. The trend in the literature is to apply artificial intelligence based soft computing techniques for complex prediction problems. Artificial neural networks which are a member of soft computing techniques were applied to strength prediction of several types of rocks in the literature with considerable success. Although artificial neural networks are successful in prediction, their inability to explicitly produce prediction equations can create difficulty in practical circumstances. Another member of soft computing family which is known as genetic programming can be a very useful candidate to overcome this problem. Genetic programming based approaches are not yet applied to the strength prediction of limestone. This paper makes an attempt to apply a promising set of genetic programming techniques which are known as multi expression programming (MEP), gene expression programming (GEP) and linear genetic programming (LGP) to the uniaxial compressive strength (UCS) and tensile strength prediction of chalky and clayey soft limestone. The data for strength prediction were generated experimentally in the University of Gaziantep civil engineering laboratories by using limestone samples collected from Gaziantep region of Turkey.",https://www.sciencedirect.com/science/article/pii/S0957417407002163,"Wen-Feng Hsiao, Hsin-Hui Lin, Te-Min Chang, ","Genetic programming, Prediction, Limestone, Strength of materials",['2008'],['35'],"['1', '2']",111-123
132,HDWT-based grayscale watermark for copyright protection,"We propose a new algorithm based on Harr discrete wavelet transform for the grayscale watermark. Digital watermark is a very popular research for copyright protection of electronic documents and media. With quick developing of information technology, more and more information was been hidden in electronic media. We propose visual cryptographic approach to generate two random shares of a watermark: one is embedded into the cover-image, another one is kept as a secret key for the watermark extraction later. This procedure would be dealt with Harr discrete wavelet transform and be left primary features of two shares. This approach is specially designed and is not easily changed and removed. After several attacks, it can still extract cognoscible graphic.",https://www.sciencedirect.com/science/article/pii/S0957417407002205,"Adil Baykasoğlu, Hamza Güllü, Hanifi Çanakçı, Lale Özbakır, ","Watermark embedding, Watermark extraction, Insertion algorithm, Harr discrete wavelet transform",['2008'],['35'],"['1', '2']",301-306
133,A systematic approach to new mobile service creation,"In spit of the growing importance of new service creation (NSC), especially new mobile service creation, most of the previous studies on NSC have been conceptual and focused on the traditional services. In response, this study suggests a new systematic approach to new mobile service creation. At first, morphological analysis is applied to identify the structure of services. Specifically, the dimension parameters are defined by decomposing the service system into basic components and the shape parameters are defined by mapping keywords extracted from business method patents through text mining. Then, by applying conjoint analysis, the promising configurations of mobile services are derived. Finally, the Kano model is applied to evaluate the requirement type of alternatives. The proposed approach can generate and evaluate the service concepts systematically. The detailed procedure of the approach is illustrated based on the case of mobile entertainment services. The proposed approach is expected to help service designers in real service creation processes.",https://www.sciencedirect.com/science/article/pii/S0957417407002898,"Ester Yen, Kai-Shiang Tsai, ","New mobile service creation, Text mining, Morphological analysis, Conjoint analysis, Kano model",['2008'],['35'],['3'],762-771
134,TextOntoEx: Automatic ontology construction from natural English text,"Most of existing ontologies construction tools support construction of ontological relations (e.g., taxonomy, equivalence, etc.) but they do not support construction of domain relations, non-taxonomic conceptual relationships (e.g., causes, caused by, treat, treated by, has-member, contain, material-of, operated-by, controls, etc.). Domain relations are found mainly in text sources. TextOntoEx constructs ontology from natural domain text using semantic pattern-based approach. TextOntoEx is a chain between linguistic analysis and ontology engineering. TextOntoEx analyses natural domain text to extract candidate relations and then maps them into meaning representation to facilitate constructing ontology. The paper explains this approach in more details and discusses some experiments on deriving ontology from natural text.",https://www.sciencedirect.com/science/article/pii/S0957417407000243,"Chulhyun Kim, Suhwan Choe, Changwoo Choi, Yongtae Park, ","Ontology, Semantic patterns, Ontology acquisition",['2008'],['34'],['2'],1474-1480
135,Web usage mining with intentional browsing data,"Many researches have developed Web usage mining (WUM) algorithms utilizing Web log records in order to discover useful knowledge to be used in supporting business applications and decision making. The quality of WUM in knowledge discovery, however, depends on the algorithm as well as on the data. This research explores a new data source called intentional browsing data (IBD) for potentially improving the effectiveness of WUM applications. IBD is a category of online browsing actions, such as “copy”, “scroll”, or “save as,” and is not recorded in Web log files. Consequently, the research aims to build a basic understanding of IBD which will lead to its easy adoption in WUM research and practice. Specifically, this paper formally defines IBD and clarifies its relationships with other browsing data via a proposed taxonomy. In order to make IBD available like Web log files, an online data collection mechanism for capturing IBD is also proposed and discussed. The potential benefits of IBD can be justified in terms of its enhancing and complementary effectiveness, which are illustrated by the rule implications of Web transaction mining algorithm for an EC application. Introducing IBD opens up the scope of WUM research and applications in knowledge discovery.",https://www.sciencedirect.com/science/article/pii/S0957417407000668,"Mohamed Yehia Dahab, Hesham A. Hassan, Ahmed Rafea, ","Web usage mining, Intentional browsing data, Web log files, Browsing behaviour, Knowledge discovery",['2008'],['34'],['3'],1893-1904
136,Detecting attack signatures in the real network traffic with ANNIDA,"In this paper, an improved version of ANNIDA for detecting attack signatures in the payload of network packets is presented. The Hamming Net artificial neural network methodology was used with good results. A review of the application’s development is followed by a summary of the modifications made in the application in order to classify real data. Application improvements are reported, solving the problems of time delays in writing/reading data in the files and data collision effects when generating numeric keys used to model data for the neural network. Test results highlight the increased accuracy and efficiency of the new application when submitted to real data from HTTP network traffic containing actual traces of attacks and legitimate data. Finally, an evaluation of the application to detect signatures in real network traffic data is presented.",https://www.sciencedirect.com/science/article/pii/S095741740700125X,"Yu-Hui Tao, Tzung-Pei Hong, Yu-Ming Su, ","Neural network application, Intelligent system, Intrusion detection application, Signature detection, Network security",['2008'],['34'],['4'],2326-2333
137,Diversity of quantum optimizations for training adaptive support vector regression and its prediction applications,"Three kinds of quantum optimizations are introduced in this paper as follows: quantum minimization (QM), neuromorphic quantum-based optimization (NQO), and logarithmic search with quantum existence testing (LSQET). In order to compare their optimization ability for training adaptive support vector regression, the performance evaluation is accomplished in the basis of forecasting the complex time series through two real world experiments. The model used for this complex time series prediction comprises both BPNN-Weighted Grey-C3LSP (BWGC) and nonlinear generalized autoregressive conditional heteroscedasticity (NGARCH) that is tuned perfectly by quantum-optimized adaptive support vector regression. Finally, according to the predictive accuracy of time series forecast and the cost of the computational complexity, the concluding remark will be made to illustrate and discuss these quantum optimizations.",https://www.sciencedirect.com/science/article/pii/S0957417407001522,"Lília de Sá Silva, Adriana C. Ferrari dos Santos, Thiago Dias Mancilha, José Demísio Simões da Silva, Antonio Montes, ","Quantum minimization, Neuromorphic quantum-based optimization, Logarithmic search with quantum existence testing, Adaptive support vector regression, Nonlinear generalized autoregressive conditional heteroscedasticity",['2008'],['34'],['4'],2612-2621
138,Two-stage classification methods for microarray data,"Gene expression data are a key factor for the success of medical diagnosis, and two-stage classification methods are therefore developed for processing microarray data. The first stage for this kind of classification methods is to select a pre-specified number of genes, which are likely to be the most relevant to the occurrence of a disease, and passes these genes to the second stage for classification. In this paper, we use four gene selection mechanisms and two classification tools to compose eight two-stage classification methods, and test these eight methods on eight microarray data sets for analyzing their performance. The first interesting finding is that the genes chosen by different categories of gene selection mechanisms are less than half in common but result in insignificantly different classification accuracies. A subset-gene-ranking mechanism can be beneficial in classification accuracy, but its computational effort is much heavier. Whether the classification tool employed at the second stage should be accompanied with a dimension reduction technique depends on the characteristics of a data set.",https://www.sciencedirect.com/science/article/pii/S0957417406002867,"Bao Rong Chang, Hsiu Fen Tsai, Chung-Ping Young, ","Dimension reduction, Gene selection, Microarray data, Two-stage classification method",['2008'],['34'],['1'],375-383
139,Multi-perspective ontologies: Resolving common ontology development problems,"Ontology – the theory of objects and their relationships – has become a hot topic in recent years, with its use for indexing knowledge and structuring knowledge in knowledge management and knowledge engineering. However, attempts to develop ontologies suffer from a number of problems in practical situations. This paper outlines an approach to ontology development based on multi-perspective modelling – that is, dividing a single ontology into multiple ontologies according to the type of knowledge that is addressed. It is argued that this approach is able to resolve some of the common problems that arise in ontology development.",https://www.sciencedirect.com/science/article/pii/S0957417406003034,"Tzu-Tsung Wong, Ching-Han Hsu, ","Ontology, Knowledge management, Knowledge engineering",['2008'],['34'],['1'],541-550
140,An approach to mining the multi-relational imbalanced database,"The class imbalance problem is an important issue in classification of Data mining. For example, in the applications of fraudulent telephone calls, telecommunications management, and rare diagnoses, users would be more interested in the minority than the majority. Although there are many proposed algorithms to solve the imbalanced problem, they are unsuitable to be directly applied on a multi-relational database. Nevertheless, many data nowadays such as financial transactions and medical anamneses are stored in a multi-relational database rather than a single data sheet. On the other hand, the widely used multi-relational classification approaches, such as TILDE, FOIL and CrossMine, are insensitive to handle the imbalanced databases. In this paper, we propose a multi-relational g-mean decision tree algorithm to solve the imbalanced problem in a multi-relational database. As shown in our experiments, our approach can more accurately mine a multi-relational imbalanced database.",https://www.sciencedirect.com/science/article/pii/S0957417407002321,"John Kingston, ","Data mining, Classification, Imbalance, Relational database",['2008'],['34'],['4'],3021-3032
141,Dynamic parking negotiation and guidance using an agent-based platform,"Modern prosperous cities strongly need advanced parking assistant systems, intelligent transportation systems providing drivers with parking information. Existing parking information systems usually ignore the parking price factor and do not automatically provide optimal car parks matching drivers’ demand. Currently, the parking price has no negotiable space; consumers lose their bargaining position to obtain better and cheaper parking. This study uses an intelligent agent system, and considering negotiable parking prices, selects the optimal car park for the driver. The autonomous coordination activities challenge traditional approaches and call for new paradigms and supporting middleware. An agent-based coordination network is proposed to bring true benefit to drivers and car park operators. These modern intelligent agents have capabilities including planning, mobility, execution monitoring and coordination. These properties can be used to construct the integrated parking assistant system.",https://www.sciencedirect.com/science/article/pii/S095741740700293X,"Chien-I Lee, Cheng-Jung Tsai, Tong-Qin Wu, Wei-Pang Yang, ","Intelligent transportation system, Vehicle information and communication system, Advanced parking information system, Agent, Multi-agent coordination, Negotiation",['2008'],['35'],['3'],805-817
142,Expert system for operation optimization and control of cutter suction dredger,"Manually controlled dredging process is of low production and poor efficiency. To raise production and to reduce unit cost, automatic control of dredging process is a desired solution to the problem. The automation of dredging operations has been actively researched by scholars all over the world for a couple of years. Based on the prior research results of dredging operations, an expert control system that is aimed to realize online operation optimization and automatic control of dredging process is introduced in this paper. Details on the problem to be dealt with and the expert system (ES) based solution are introduced; the focus of this paper is put on the architecture, knowledge presentation and inferential mechanism of the ES. An expert control software program is developed with C++. Based on the test platform constructed the performance of the ES is evaluated by comparison. Experiments show that the expert control scheme presented is capable of realizing automatic dredging process control with acceptable performance.",https://www.sciencedirect.com/science/article/pii/S0957417407000954,"Shuo-Yan Chou, Shih-Wei Lin, Chien-Chang Li, ","Automatic dredging, Expert control, Knowledge organization, Cutter suction dredger",['2008'],['34'],['3'],2180-2192
143,On the development of a technology intelligence tool for identifying technology opportunity,"Technology intelligence tools have come to be regarded as vital components in planning for technology development and formulating technology strategies. However, most such tools currently focus on providing graphical frameworks and databases to support the process of technology analysis. Techpioneer, the proposed tool in this paper, aims to offer decisive information in order to identify technology opportunities. To this end, the system uses textual information from technological document databases and applies morphology analysis to derive promising alternatives and conjoint analysis to evaluate their priority. In addition, the method used in developing a technology dictionary is presented, employing clustering and network analysis. This system also has the ability to communicate with experts in order to estimate the value of existing patents, which is inevitable for the priority-setting of alternatives, construct a morphological matrix and so on. This paper presents the system architecture and functions of this tool and moreover, illustrates the prototype implementation and case study of the same.",https://www.sciencedirect.com/science/article/pii/S0957417407002175,"Jian-Zhong Tang, Qing-Feng Wang, Zhi-Yue Bi, ","Morphology analysis, Text mining, Technology intelligence tool, Technology opportunity analysis",['2008'],['35'],"['1', '2']",124-135
144,Automatic expert identification using a text categorization technique in knowledge management systems,"Since tacit knowledge such as know-how and experiences is hard to be managed effectively using information technology, it is recently proposed that providing an appropriate expert identification mechanism in KMS to pinpoint experts in the organizations with searched expertise is more effective and efficient to utilize this type of knowledge. In this paper, we propose a framework to automate expert identification using a text categorization technique called Vector Space Model to minimize maintenance cost of expert profiles as well as problems related to incorrectness and obsolescence resulted from subjective manual profile processing. Also, we define the structure of expertise consisting of activeness, relevance, and usefulness factors to enable deriving the overall expertise level of experts by analyzing knowledge artifacts registered to the knowledge base. The developed prototype system, “Knowledge Portal for Researchers in Science and Technology”, is introduced to show the applicability of the proposed framework.",https://www.sciencedirect.com/science/article/pii/S0957417407000218,"Byungun Yoon, ","Expert identification, Knowledge management system, Text categorization, Portal",['2008'],['34'],['2'],1445-1455
145,Toward supporting real-time mining for data residing on enterprise systems,"As data mining techniques are explored extensively, incorporating discovered knowledge into business strategies gives superior competitive advantage to corporations. Most techniques in mining association rules nowadays are designed to solve problems based on transaction files transformed to horizontal or vertical format. Namely, the transaction-normalized tables should be transformed before such methods could be applied, and some previous works have pointed out that such tasks of performing data transformation usually consume a lot of resources. As a result, traditionally, data mining technique has seldom being applied in real-time. However, in many cases, the decisions have to be made in a short time, such as the decisions of promoting fresh agriculture goods in retailing stores should be made daily and in the limit of one or two hours. This study therefore proposes a new method which incorporates mining algorithms with enterprise transaction databases directly to perform real-time mining. In addition, the proposed method has following advantages to support real-time mining performed in enterprise systems:•raw data of enterprise systems are used directly,•when the threshold is tuned, only newly qualified data are read and the data structure built for original data is kept intact,•product assortments centered on particular product can be effectively performed,•the performance of the mining algorithm is better than that of popular mining algorithms.",https://www.sciencedirect.com/science/article/pii/S0957417406003496,"Kun-Woo Yang, Soon-Young Huh, ","Frequent patterns, Data mining, Enterprise databases",['2008'],['34'],['2'],877-888
146,Nonlinear predictive control to track deviated power of an identified NNARX model of a hydro plant,"This paper presents the performance study of predictive control approach in application to hydro plant. The tracking on deviated power as reference signal for identified neural network nonlinear autoregressive with exogenous signal (NNARX) hydro plant model is studied. A detailed plant dynamics constituting various hydro-components and -structures are considered for identification of its corresponding NNARX model. In obtaining an appropriate NNARX model structure, the plant is simulated on random load disturbance variation with input as random gate position and output as deviated power. With the identified model, a nonlinear predictive control (NPC) strategy is applied using Levenberg–Marquardt (LM) and Quasi-Newton (QN) algorithms for optimization of control performance index (CPI). The study also describes a control approach involving extraction of linear model from the neural network (NN) model, based on instantaneous linearization theory. Its tracking performance is compared with NPC on different nature of reference signals. These control approaches are applied so as to cause model output track on various deviated power as a reference signal.",https://www.sciencedirect.com/science/article/pii/S0957417407004010,"Yu-Chin Liu, Ping-Yu Hsu, ","Hydro plant, Random load, Identification, Deviated power, Predictive control",['2008'],['35'],['4'],1741-1751
147,A fuzzy CBR technique for generating product ideas,"This paper presents a fuzzy CBR (case-based reasoning) technique for generating new product ideas from a product database for enhancing the functions of a given product (called the baseline product). In the database, a product is modeled by a 100-attribute vector, 87 of which are used to model the use-scenario and 13 are used to describe the manufacturing/recycling features. Based on the use-scenario attributes and their relative weights – determined by a fuzzy AHP technique, a fuzzy CBR retrieving mechanism is developed to retrieve product-ideas that tend to enhance the functions of the baseline product. Based on the manufacturing/recycling features, a fuzzy CBR mechanism is developed to screen the retrieved product ideas in order to obtain a higher ratio of valuable product ideas. Experiments indicate that the retrieving-and-filtering mechanism outperforms the prior retrieving-only mechanism in terms of generating a higher ratio of valuable product ideas.",https://www.sciencedirect.com/science/article/pii/S0957417406002971,"Nand Kishor, ","New product development, Case-based reasoning, Fuzzy CBR, Fuzzy AHP",['2008'],['34'],['1'],530-540
148,Grouping of TRIZ Inventive Principles to facilitate automatic patent classification,"Automatic patent classification facilitates searching for previous patent documents. For TRIZ users, they would like to search for patents based on the solutions (TRIZ Inventive Principles) to the Contradictions addressed in the patents, which is different from traditional searching for prior arts based on the application fields of the inventions. For this purpose, a TRIZ-based patent classification expert system is needed. To facilitate automatic classification of patent documents according to Inventive Principles (IPs) for TRIZ users, we analyze the original 40 IPs proposed by Altshuller. Seven IPs are defined as Obscure IPs, the other 33 as Distinct IPs. Furthermore, two kinds of similarity among the Distinct IPs are defined: text similarity and meaning similarity. Then the 40 IPs are grouped into 22 new classes. Automatic classification based on 674 patent documents associated with these 22 new classes is tested and analyzed, with two issues of multi-label classification and class imbalance addressed.",https://www.sciencedirect.com/science/article/pii/S0957417406003307,"Muh-Cherng Wu, Ying-Fu Lo, Shang-Hwa Hsu, ","TRIZ, Inventive Principles, Similarity, Patent document, Automatic classification",['2008'],['34'],['1'],788-795
149,Mining customer knowledge for product line and brand extension in retailing,"Retailing consists of the final activities and steps needed to place a product in the hands of the consumer or to provide services to the consumer. In fact, retailing is actually the last step in a supply chain that may stretch from Europe or Asia to the customer’s hometown. Therefore, any firm that sells a product or provides a service to the final consumer is performing the retailing function. On the other hand, product line extension, which adds depth to an existing product line by introducing new products in the same product category, can give customers greater choice and help to protect the firm from flanking attack by a competitor. In addition, a product line extension is marketed under the same general brand as a previous item or items. Thus, to distinguish the brand extension from the other item(s) under the primary brand, the retailer can either add secondary brand identification or add a generic brand. This paper investigates product line and brand extension issues in the Taiwan branch of a leading international retailing company, Carrefour, which is a hypermarket retailer. This paper develops a relational database and proposes Apriori algorithm and K-means as methodologies for association rule and cluster analysis for data mining, which is then implemented to mine customer knowledge from household customers. Knowledge extraction by data mining results is illustrated as knowledge patterns/rules and clusters in order to propose suggestions and solutions to the case firm for product line and brand extensions and knowledge management.",https://www.sciencedirect.com/science/article/pii/S095741740700053X,"He Cong, Loh Han Tong, ","Retailing, Product line extension, Brand extension, Data mining, Association rules, Cluster analysis, Knowledge extraction",['2008'],['34'],['3'],1763-1776
150,Compact fuzzy association rule-based classifier,"Classification is one of the most popular data mining techniques applied to many scientific and industrial problems. The efficiency of a classification model is evaluated by two parameters, namely the accuracy and the interpretability of the model. While most of the existing methods claim their accurate superiority over others, their models are usually complex and hardly understandable for the users. In this paper, we propose a novel classification model that is based on easily interpretable fuzzy association rules and fulfils both efficiency criteria. Since the accuracy of a classification model can be largely affected by the partitioning of numerical attributes, this paper discusses several fuzzy and crisp partitioning techniques. The proposed classification method is compared to 15 previously published association rule-based classifiers by testing them on five benchmark data sets. The results show that the fuzzy association rule-based classifier presented in this paper, offers a compact, understandable and accurate classification model.",https://www.sciencedirect.com/science/article/pii/S0957417407001339,"Shu-Hsien Liao, Chyuan-Meei Chen, Chung-Hsin Wu, ","Input partitioning, Fuzzy clustering, Associative classification",['2008'],['34'],['4'],2406-2416
151,Seeding the survey and analysis of research literature with text mining,"Text mining is a semi-automated process of extracting knowledge from a large amount of unstructured data. Given that the amount of unstructured data being generated and stored is increasing rapidly, the need for automated means to process it is also increasing. In this study, we present, discuss and evaluate the techniques used to perform text mining on collections of textual information. A case study is presented using text mining to identify clusters and trends of related research topics from three major journals in the management information systems field. Based on the findings of this case study, it is proposed that this type of analysis could potentially be valuable for researchers in any field.",https://www.sciencedirect.com/science/article/pii/S0957417407000486,"Ferenc Peter Pach, Attila Gyenesei, Janos Abonyi, ","Text mining, Data mining, Literature survey, Information extraction, Categorization, Clustering, Classification",['2008'],['34'],['3'],1707-1720
152,Recommending trusted online auction sellers using social network analysis,"The reputation system currently used by major auction sites to recommend sellers is overly simple and fails to take into account the collusive attempts by some sellers to fraudulently increase their own ratings. This paper presents a recommendation system that uses trading relationships to calculate level of recommendation for trusted online auction sellers. We demonstrate that network structures formed by transactional histories can be used to expose such underlying opportunistic collusive seller behaviors.Taking a structural perspective by focusing on the relationships between traders rather than their attribute values, we use k-core and center weights algorithms, two social network indicators, to create a collaborative-based recommendation system that could suggest risks of collusion associated with an account. We tested this system against real world “blacklist” data published regularly in a leading auction site and found it able to screen out 76% of the blacklisted accounts. This system can provide warning several months ahead of officially released blacklists to help guard against possible seller collusion and can be incorporated into current reputation systems used to recommend trusted online auction sellers.",https://www.sciencedirect.com/science/article/pii/S0957417407000437,"Dursun Delen, Martin D. Crossland, ","Online auction, Social network analysis, Center weight, Information asymmetry, Recommendation system",['2008'],['34'],['3'],1666-1679
153,Automatic tropical cyclone eye fix using genetic algorithm,"Tropical cyclones (TCs) are weather systems with vast destructive power. To forecast TC tracks, forecasters need to locate their circulation centers, or eyes. This eye fix process is often done manually in practice. Since subjective elements are involved in the process, forecasters could disagree on the results even when multiple factors are considered. This paper presents an objective TC eye fix method that utilizes genetic algorithm to search for the optimal values of a six-parameter TC model. The results of this study indicate that the proposed method gives the best average error of 0.127° in latitude/longitude on Mercator projected map with respect to the best track data. This is well within the relative errors of about 0.3° from the results of different TC warning centers. The method can process 6 min of radar data in about 10 s when implemented on a notebook computer, meeting practical real time constraints. It provides a practical, independent and objective source of information to assist forecasters to fix TC eye centers.",https://www.sciencedirect.com/science/article/pii/S0957417406003150,"Jyun-Cheng Wang, Chui-Chen Chiu, ","Tropical cyclone eye fix, Meteorological computing, Genetic algorithm, Weather system modeling, Weather forecasting",['2008'],['34'],['1'],643-656
154,Making CN2-SD subgroup discovery algorithm scalable to large size data sets using instance selection☆,"The subgroup discovery, domain of application of CN2-SD, is defined as: “given a population of individuals and a property of those individuals, we are interested in finding a population of subgroups as large as possible and have the most unusual statistical characteristic with respect to the property of interest”.The subgroup discovery algorithm CN2-SD, based on a separate and conquer strategy, has to face the scaling problem which appears in the evaluation of large size data sets. To avoid this problem, in this paper we propose the use of instance selection algorithms for scaling down the data sets before the subgroup discovery task. The results show that CN2-SD can be executed on large data set sizes pre-processed, maintaining and improving the quality of the subgroups discovered.",https://www.sciencedirect.com/science/article/pii/S0957417407004058,"Ka Yan Wong, Chi Lap Yip, Ping Wah Li, ","Subgroup discovery, Scaling down, Instance selection",['2008'],['35'],['4'],1949-1965
